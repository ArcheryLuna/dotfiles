{"_id":"@mediapipe/tasks-vision","_rev":"176-f82b4feb6f6724aaf99c38f691eb16d0","name":"@mediapipe/tasks-vision","dist-tags":{"latest":"0.10.10","nightly":"0.10.11-rc.20240228"},"versions":{"0.1.0-alpha-1668420867":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668420867","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","module":"vision_bundle.js","exports":{".":"./vision_bundle.js","./loader":"./wasm/vision_wasm_internal.js","./wasm":"./wasm/vision_wasm_internal.wasm"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","dependencies":{"google-protobuf":"^3.21.2"},"homepage":"http://mediapipe.dev","types":"vision.d.ts","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668420867","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-9DjQywHEnHJ1+hDRw7BaxZXc6ECwiDT2QGt3WKkwIbc+6HZWdQaMwXjW819xCDCu2E/Y3xr7xJJXjnPiM8rvWA==","shasum":"5fd9a6f5f691231ea5dfe5e61d35f6eda3f1b4c6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668420867.tgz","fileCount":5,"unpackedSize":10428186,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIDG1uEUHUMXK+HjRU3MYwueYLtvzULmbsAFaSjdz/3G1AiB+nrC9b8h2TbFXsmj36v+LgHXHc66/baGi0SigLMJJ1g=="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjcqQDACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmoWRxAAnyFmC8dLBlDQuHrj5gGee4kXi8Qmu2MhflNGuzdLfJ1d3/tD\r\nYEnqGz4r33Fc5E+CSAjPRVxqS6DucfPVsjYOTmctaHyS1BXQD4eCaxOciijy\r\no2vpLdIrOp6Ra3odlDbqtX269ZNTw8UZdv1S/zGBfcQQ0/5hU9B9GEwCJJbs\r\n1h+1xNv92KLCLXU2WqGCFOB1K/ETbfmtp7PlnJUd3zwAcHbb/kMy7yTUJn/A\r\nDPoLiWXpCf73p7PRxVwnKs0x0OXsiTLX62sXuS3F6SWYfsV2kztKU+1M4Tp+\r\nMUzBkLNEIXXFx3+71TQ3ET+KOSJm6NgJIW2GpHO6fOwDr2vgO/2WaENzvi5W\r\n7oAkLFdeReIR4hryLcAe0uPgYY3Hz1qi9MT5jbX0K2ncSP41C8KkiW+VDkdV\r\nAPFtHdHXZNTfka3KojXusTluraZl6af12qFBaaqeM5W2X1uTmvU5Hj8atuIY\r\nerv4BP01iNeHJGVKTRDGCEDdF6iHq4YwW8vv5LVsOLHromf8NtXfsgeN6pcm\r\nYW5RJOCl7zhJSYt1JMEE2UIsDB9e6zVqSZ2ACDhUz6xYpeh/qVJVHcxf8BOi\r\nhY8SD4SiSw3rLvnlV/9fryiiSeqUNgkMY7hVpomjqdg9dVo+jfmpTlARNgT9\r\nualjthR9CweJsT+jZ3qMpcIoB5mj/PNxiU0=\r\n=zUKu\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668420867_1668457475564_0.6452519794603611"},"_hasShrinkwrap":false},"0.1.0-alpha-1668420868":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668420868","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","module":"vision_bundle.js","exports":{".":"./vision_bundle.js","./loader":"./wasm/vision_wasm_internal.js","./wasm":"./wasm/vision_wasm_internal.wasm"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","dependencies":{"google-protobuf":"^3.21.2"},"homepage":"http://mediapipe.dev","types":"vision.d.ts","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668420868","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-KUTKeU7s41cKAvVtm4WYuqTF8ytpsSZARJkJ8t4aIHS4YTuzxKoR5OOkspnnq3hDJfr79wp/OMewePQpSI9xpw==","shasum":"e9a7c2d21d869186bc24259855035955739b5569","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668420868.tgz","fileCount":5,"unpackedSize":10428186,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIHGwc98s5kAVKedRXgSQf07ITlpbqJog+wxxZSc15j2qAiAHcU2+HD4qiZlJxRJpbu/HbC3BbjPltf06JAdrwIXihQ=="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjcqeaACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmr+yxAAkO7R3oSVFBMB+h4utY65mB4l3DaChOY1oxEv8nT17wPpuTPx\r\ntaNizbqVfXAdE75X4G4qrTkibppIK2+wH9Sbtnw937bXW30AVWn68B6HRRFb\r\nPuV+sLBO31nP76xn2mSkFTwo6em0YPm/5Gf3HViwhqr48z/VZNGX7hBSW/uv\r\ncQS7yuj64mNB9/JrPJgJ3VKb4yQGSgiYc6OT1xjx3Aepfy7RWI3RmGiVokjm\r\n8S2Q4TKYUi0mDWjJvfwHeQ6jtJTZ8d8GupXq2ZT4LRwCC4mD6jkecyAxT5iB\r\n3DI9Z8dPpyk6FfxFPJuA6846eaOMSxxDSQQLnaa9JssB7w0ex7rl6Ssu6pKy\r\nomXFQ1OpJObh6ui9WOXMNYdHOBWXRjVhIo+DPRD79Nb4sgbkChh7QVgXsq8z\r\nVuxph0W4QHziFZW9UEIZHLNY2lwDX+sNuXJxMDH54C5U7Bny/UItz+CLKm3t\r\ndi/uM+nKOaOfgfDe/V3iKfWNWtMz2w9q6e2fqNfFNKffaJe1gEylXXFYbhzT\r\niJcoXFWvaK8r+RugNQjWdaU9OfAGri8gIFHUhPgYoppN9k2BD6/jYk5rPt93\r\nR6vYyqiD6SXebVvzLKn4+EsZJziAX91h+QWoMqCpZrrwSzsAfNwEN1Dn9zUM\r\nuaTQd/eDsj61n61ri1puN9wKeeZbTqSLa7o=\r\n=LAdz\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668420868_1668458394669_0.16514615234667263"},"_hasShrinkwrap":false},"0.1.0-alpha-1668548448":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668548448","description":"MediaPipe Vision Tasks","main":"vision_cjs_bundle.js","module":"vision_cjs_bundle.js","jsdeliver":"vision_iife_bundle.js","exports":{".":"./vision_cjs_bundle.js","./loader":"./wasm/vision_wasm_internal.js","./wasm":"./wasm/vision_wasm_internal.wasm"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","dependencies":{"google-protobuf":"^3.21.2"},"homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668548448","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-N7W/BqYFxaGer+w64IAonElQeF6Nb5rhvGg9t1KQf4ZWHf/Ek+Pp8F7jRecmTiKS5VutWKVOVgKGeur11M5AIQ==","shasum":"6aba968eba27438fe434f392c26ee725065d6007","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668548448.tgz","fileCount":5,"unpackedSize":17756039,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDpG+of75klF7+2uu9jS5HOzAcSIh7gmaKgaFwEyGYrNgIgIRBZB1XyX1gNCwQ6SSfpb2Js6T1cLQOhuqAFK6ooSLc="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdAmkACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmpy0RAApML4O66KDY0fPRZP2avzRl5n4v88hv1vEyviczqQjGz8EgIG\r\nEYnyb+rMyzfB3kfbzP/Yy7DAIEmURl6aOxc56RmgIpk9yVjgc0yQYPzI2s5l\r\n3S9wel8M9Q2xG7E14V0vuSZU2NLLjHFljUrz/yUdFZ7jnYE+YL+IcNvS6uQA\r\nWpuVnURnxEPZvkkGrrlXTQUKlKcsqjmfKwOaHHkkNsyX4RUyKGrOJ+DlSUkA\r\nGS5zYFhVKTi0ZVFc1GGsUI9BB80Qjboudcjj4w1/9r1QPaJYyfMbGy0X6jg3\r\nskD7DOE1iQCAFFWaDBK8hmcNBFR/LN91AnHBkue7nIh+nXSW6HZK7m7goWO9\r\neOajA13WZlBp9i67wO/DY2DXeGVlyO233viU1ZrX3TZqh3W8DaKBKwufUQcs\r\n7pPc+WLbW/QDS1laEZVxzPvm89BKHh1TVj96IOcIxa06penIPSI5vIZ/NjRi\r\nNPipcjtuGzfiJElCMpGlNPko6kLqewfJgV0bkj1tqh8VRg8m7GjiD8QEpEA3\r\nWS9OpSdyD5gHWSpVpAOMOIdtU/bv8X1oiw3JSvQs67D+pPxGMpz1EHouNOif\r\nu6HZIoghkrCsIyueQv7dSBSH9hSQhIgkItakC7RRSNHs2V7a5QHnfFf8FtiI\r\nsB2C5kfdu/JsKuCoTNw/ziYSHlp2L5pToIo=\r\n=VO7w\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668548448_1668549027709_0.8520581250020061"},"_hasShrinkwrap":false},"0.1.0-alpha-1668548449":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668548449","description":"MediaPipe Vision Tasks","main":"vision_cjs_bundle.js","module":"vision_esm_bundle.js","exports":{".":{"require":"vision_cjs_bundle.js","import":"vision_esm_bundle.js","types":"vision.d.ts"},"./loader":"./wasm/vision_wasm_internal.js","./wasm":"./wasm/vision_wasm_internal.wasm"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668548449","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-RapWILoioPIVF1xRVNNIy87E1u+M9bpbc4jLH8LVUphFQHkFT+HoDQNsp+G/cwTfUEFSdmCiid7L6X43fm25Zw==","shasum":"5570701c3654c7ca0e062e4360f48caa477c1ed9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668548449.tgz","fileCount":5,"unpackedSize":8724905,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIDkjsdae75dc7zb8CKIXxW/6ErsncN3Em8prO5l5/GFUAiAWFF9nejxptrDTH94473EyfP2Q4GmgEedN9AyTIjzznw=="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdDtWACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmr2fQ/9GiPC0olr9BEiqt8EIK29Z61c9p9iDF5oS7TZKFUbDi8PvD7D\r\n0i0E2UGD3dWIZSN6EzNxTvgfKMkdd/XjeyT/cpNxRBKMabznavvcZRXOwNQy\r\nJkX82y6259y8BAsM7wjS+LZEjCwzYuigN1nwv5S6KNxb61ViRf6g9ZExib4T\r\nXLnutJlHGH5rGNNg6YI3mCs8pAaxb/ECQPnUjDbuAgF2yv2idTSKdFrj74Y0\r\nIYIiRNuqukHNNVh72yPB/DA68IQslHhMbqqpvSYkxXDWeKu76mL0CKRgr7T6\r\naER2D2alj4LFNGePUqQJj+HTWGO9VTIkF0hJfdhR0Eg0YGznn9GxcHtshTY8\r\npa3Qgn5+xIFgBgpIdEOV0ssLqbP/Q6uUD8rKYxSie/tY0XwQWUspaoyAYLiF\r\n3Y+9HVe1GLK27HEruiXPFNlUlYk6R3caP8SCRZfFKFINnykxx3AY+kN9zy0d\r\n+0OYRFLUt9Wmy+Kzu15xgisOIiiWq7f8Y95qP67855flZvlNdUs6Zago1azs\r\nN0LqH6SE6XSMyzzjpteBCh9vPBN3AXlp54p1FswPdydrqI5XvPDyxlcUVfzd\r\nl1FjsZJ25GDhADH7jISrtgZQtTHz13kLQmk/QhsdZSKuUNpwcXBSQpjja9zX\r\nqXXl/w3RX7uO5O6DzZ8NSnMnbAPUSneBJe4=\r\n=Wcor\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668548449_1668561750344_0.7837442883062504"},"_hasShrinkwrap":false},"0.1.0-alpha-1668548451":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668548451","description":"MediaPipe Vision Tasks","main":"vision_cjs_bundle.js","module":"vision_esm_bundle.js","exports":{".":{"require":"vision_cjs_bundle.js","import":"vision_esm_bundle.js","types":"vision.d.ts"},"./loader":"./wasm/vision_wasm_internal.js","./wasm":"./wasm/vision_wasm_internal.wasm"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668548451","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-3AAwW1V3iY6xgYETams0t8E8vEXeE5CIdLBDrkGmB0mwVUolRkdA6sD/nhzAGcLgw9/mXrMiCro4p5+/aHEzcg==","shasum":"23854007989c4b9c28c9eaf70b57a96f1f9afdbe","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668548451.tgz","fileCount":9,"unpackedSize":8791760,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCID5w0hvsewVkB6w1jpjoDLo3697b00U08Y9u/D9JClZ3AiEA0u/bL2yEo2/TVOlWaonlCNt4YHI0co6oGjDl4dwjIEw="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdHMQACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmrvEw//Te4QhRCV5IK7opMFZ00qVED9RfZhyQSJuPg1gVDcfExnJQhE\r\ncZMWs1K6OR0Pmc/kPicE+U/K6TGw6/UITN014gQ1eAffTGNB1VQ3FSeGI4xe\r\ncAkBEUhX2H6g8mn4+ANxzSEHDkyDCYeUPrrURQqwSDCabUWWanxvdSxrHStm\r\nxhtV+IpY6jSpfmUBI62o+lVxslbVNy9bdT97NpsRTvLBLMocvyJSg28NRzNf\r\nTVvBJfWWT3ez+4UVdRc85tj3VBlO6/wLJScinG3EtuwDDWoVl+j3IoorbhFA\r\nZGgN8DrvfbKJ4nbEpFScpkGPMjVmUqnM8MJo3I0FPaL5zv76aX9X25PYNPtZ\r\nnYrjsFPFk7B3lcwmW9yYs+qQQiiPiEC6Z/vNfERqtsewNCJgqzSOx+mtwgnG\r\noU6LcIhQ0RraoHJdadPZ9GPle4oCKy9jsGZ0UG2PO1zntWdG0QdOfc24F4YU\r\nT9Q8KMXvCgWk6qO9XUOeuQIVtT0xgsBrAyuSEy0+3Y16x15tp7uIQq9qJUd4\r\npe9fD7w0pJt4kmTdADX0YCQlyOr8/V0I+2rKJdouiJwOE+et0kaq+tRQ2wx+\r\nLzYlomkkz5FJfC4Ct4e7wcmL+deLADILumntIfdmuPpPQ72hQieUpXAGX/oQ\r\nqnZ2jkeiM52/XB/R3Qp/EwYQCgErAER20g4=\r\n=FPV8\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668548451_1668576015744_0.9738107770604134"},"_hasShrinkwrap":false},"0.1.0-alpha-1668548452":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668548452","description":"MediaPipe Vision Tasks","main":"vision_cjs_bundle.js","module":"vision_esm_bundle.js","exports":{".":{"require":"vision_cjs_bundle.js","import":"vision_esm_bundle.js","types":"vision.d.ts"},"./loader":"./wasm/vision_wasm_internal.js","./wasm":"./wasm/vision_wasm_internal.wasm"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668548452","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-tHoQJTG+I8nkYTIYpnZRH8Z6Tarv0NNeP9MXVso6uAt3EjPJAEL7v4973fatYRjN1Z72lRIJos/wnCaMpt54XA==","shasum":"7f36e56ea84995e35270613e3ed1a13cb686a1a3","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668548452.tgz","fileCount":9,"unpackedSize":10236753,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIF5+RDwBpk0i52YCTAWnEP5GXRVb+EmnR0UHIyTSf11sAiEA5h6Sjr52rneiDP60dKbTu7Jtr4TkfQJj7gEnxG0qzfY="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdHwiACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmqrFRAAjRAH/BWJ1QzZPCF6Tv2rrA8TpsFGyy49qnZjg1F0j2vB31QN\r\n43XiPOxFSlzcMWGXlrSen3OH0n38WYA/tM0cBRn4Ox7rhgnPPyjDIGhyakEq\r\nDaZs0i3/S5wyf6oNby5N/iASM0eoRl32wc8WyAJqBLcqtO0BE23tXGRxwkpv\r\nzUtk7FS09N4m/o9QmSOjyERnsJgdk1k9vhichrBPdBKpsFyUjgShjB11ppBf\r\n3Ly025bbZlABj6B7sVuCOqpSDTfKzzdLbDdCJ+VTaFS9bzn+SRM6SeGrE7oU\r\nj0asgbD3yq0ZPSzC6gTduEgHEBYPHmVLY/un8jaL5k1K8VVzjouImKO+6x7E\r\nlACK4GV9WZatjjORpirnjlxtbD6esUJ4LZwA6g7jpUqCFzyVRpbiWvuq684f\r\nj6GxqEqV9DhleDyP2IV+zxfBniAzzHXk9/286qNFvImJECHxcAa0s/PKzo3T\r\ndxTvDq5kx+ctCqlhQ85fC7o1nMeI9UEtjiLvTkJbCrebT/UpS9iUjKSOGdwS\r\nWrumJITsO9/lMjidUVgAWHfsDv+6c1MKRv5p0FPNm3K4jSypAxnu3oybrb1f\r\nkv22b5mW5DnGmqhI5OD5n4euRvwh6zZx7aNMdiPi5ceIOwpDJLLByRdrfld9\r\nq/zOcA5qnzFRTopyvXkyzWABegX9tUy9wpc=\r\n=NKRc\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668548452_1668578338127_0.11846440926596125"},"_hasShrinkwrap":false},"0.1.0-alpha-1668548453":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668548453","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668548453","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-y8PTbvThsqeBcyhCdmoYmXZZbHI4EpwWXEaSy/IAYrBboN3InpxMgTCFOxIRxnK4O9LFtP5VT1KaD2o5qhPHZg==","shasum":"9097509beaa936dd03bbc4066b1664bdfc68d1f9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668548453.tgz","fileCount":8,"unpackedSize":8194452,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCXoMJ6uBQ22q1EJm5KFYNlX50ADRD5rSQoa8MoxJNXGwIgW8NqZWKB1agDnM/ZRKWI1QB7OCKV1qTTCUfc4tzU0Qg="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdIaEACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmrQ5hAAlBl46pfm+7uLKrQiOeTuPNOaJVfBVkPAK85wW8ZKBplVna0M\r\n21/sBljxQ5puzgaGmkHVcWqs8NDwZIuV/viJcfD9ULDXyUATLGDqMsW0Dyj/\r\nU4uNhTWZ7Tcz5ignLIu/fDHV7TbmFZ7eGM9J9Eb7nT0TiQf/8NiTX99rTHqD\r\nwYqb68ilPFvksaWm5tEjy1ANIzr3AhE6tI4o2gxvFf3oEulhOwAE90BVUNXK\r\nwwINx6qmKIGFnZF1X4Vevk11gBuk6EQAKeKYlA1oADRpBi66FaSS/151siVq\r\nEfHa6RJKNrJR9sf19qJPsyHdHz9FFTnyH0NYfDGzk6kW3xdZ0ciRENsNc8SZ\r\n4hc2Mo5b60M3nR+DBxs/74oey/XgWX0k1Dmz8eLOZA/rgh1TADNdTFsjZsyV\r\n/vHpg7jlSEEwq2u4NIM22D/M8b3aXXF2UtTv9oN/dhJWjTl9IPPqz6funYek\r\nSgTp5Z6AskIdGhU9/lRlhaWGYHMGItouaiF/Nrxb4guh0GRxC10u+NvNtZ4r\r\naF50oM1lI6tiV5uwR+PCZMx+qNg7qLvN3qWLthUEr/8HRBSV7awXkCVEKiLV\r\nzl78FNnXXRKIHf28JpBjIsHvrO1DfBqPijlb++rSsY3M1Tr14ECw/Wi6scV6\r\nZkVTBVXmKt7ey9DfwGS6DEdIfKOy1r1cWmw=\r\n=nqdR\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668548453_1668580996690_0.40391997548712033"},"_hasShrinkwrap":false},"0.1.0-alpha-1668548454":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668548454","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668548454","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-vsO94sziL+xh7y8wXBI1j9QNw7RpRlJU9EGiJ5QNPlV3DPe3/G0sNw6EIx8yn96RWocW8V7KsAl59JfNiDp+Kg==","shasum":"a75091eb5d218f94f748750fe1b4966c6686300e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668548454.tgz","fileCount":8,"unpackedSize":8194089,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIA8V0WzQDjk9ua2HITmSNc1o64Xx17Yads6teX7Umb/dAiEA3uALlZYWWGe4SXosRojw30u/eHWozjGvM2JLA20PvSA="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdJNSACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmrCgw//WZaGroXjyxs7hBTZSgtX68RmE+AvlMzQSaX1JPunrkA4Na5O\r\ne8tCzuvqXHhe9P+h1sYHyBcweWvFK2BwDEtUcerGwODF9VfSz2bSWsKuswRG\r\nzt0/HDHENDp9czTIw8Z/vJoE2yd8aaGCcACA6+t4RaJhlInRriDVOoZKHBjb\r\nuP//K1BR9VEFgnjU/IOFGNsoJToVvyRApOsv3NIBnt+gw2g0zovdV8ngqoYw\r\nXYRYM1qJlY65F1WhGB/NtznDZOxxT5IRjupaaUCe6O4wnLPaEB8a+lPC4PF4\r\nPpESMK3ek6eVdxKqKGd+szTBeqoNdauQC1O9pHf3pPrv0ig1Nj4lg9fnUbPo\r\nEaShy/wUYQm7UyWh2dEEyJ3l4DwiEnQmM3UuPtn6/T3BPfROU7gZBZKv6NJ2\r\ng8UtKQ8NxiYRKp2t6cncCjWjWfKp6w0poKdEUKSd6oIoXpcaa2wqx00pqewK\r\nPC7gyP2hz642BKb7UV78cSI3kzKy+QA53jqn5h0qnlUcOre44jizAN0/RWOl\r\n1Hg0eEWLUlhibvcjAmp1Bk27wuX+I3OuW2wE9L2SCvvlVjgI/JI7LMjDqnkf\r\n4Yh4IrWZLEdpVXWtqcdxED6ujAmHxlmCxYTmo9DjXYhJffXMXLf1Ol2iBGfy\r\ns4IC8fnFS3GIpjqf+HCxJQFiQqqG5cc/1jo=\r\n=P/vZ\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668548454_1668584273701_0.817522070180619"},"_hasShrinkwrap":false},"0.1.0-alpha-1668655831":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668655831","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668655831","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-d3WpNHmxs05hFl7fpdJwu3TpEY3Y473gVT3NhumFolV4tPR5BTGUnmmobcK20O3HA/G/QUSEjk2SDIqACeuvhw==","shasum":"8d77298c9b6c7289de2053e373487a40155080c2","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668655831.tgz","fileCount":5,"unpackedSize":8216971,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCVbieauExSun1chApn3k4Y5/f+Mk3wYWztT1ZRk1ffngIhAPNygaOTPGQywxLzeHL8GCVhdllI+5QgXuQdnZY28ieW"}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdbEXACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmp53hAAnSnrJkGLIJzwhHVXysu78INnrh6XgQr109BlYpSrf5xiIrE3\r\nVoynnzKJ8dqiJa+exNJb5hx1edqYoQqTOib0bGRnNU4EvRsC64M+zrAtrtdO\r\nnlLk4wjYdNBtfMAXd3kTl/KCIzqhzElqjRwFsJvAiINTdLaK6Rqdo61/NcEu\r\nrd3CMYtzolF/wNcqDlmdra1qbh6G7oHn8VfirfD4Ks+n9CeeMvfVmGmo4JG/\r\n3WRxERcpXSx/4sBqWv8iCL0hkbBC/3rovHe2HFo/hUod64fToDgWNazEs1Lc\r\nq8jV8sjccIJhIUVKZaG+v/iZY9p5ijh4w5XY7Tv15Z9VjBoU1zWF1V7deFCz\r\nlov1zW99kYyC9TGRdpBwn/v8W1wgBNvJOQl/B+eV7sOBkVL1TaOc+JzbDaWt\r\noUcAJ8aLgQaGuRvvD9dp3ptbDjnRoaaIJSnUUmONPeIhXboxGuhCWvSb0zou\r\nYqAC42PMzW27p6tHKLWSA0fSlAn2C0KjFUSy6Qpc5N+OAa2GHsCXLzhyVcxY\r\n+GK9xyy/DjWfpyttevsJYOlruQC81U0rgZ0T3tFEOjM18yNYWU4vGQyyXaE4\r\njQ4oc/rZmW45ijqL0V1N7M3CSKDAU0dV/800in/Ajp4NR/Eg8G3GZn2J7yh0\r\niXCg/mj//T6Od8uy3rQzpM0Zf0ntJm4aAJY=\r\n=WFrr\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668655831_1668657431242_0.9672423770234198"},"_hasShrinkwrap":false},"0.1.0-alpha-1668661712":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668661712","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668661712","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-szY6Yf3HOQ0A/P/A54jziAlAkaqUbFtT+L5SEJ3g62znYwQtWs8Bod0CYKmYakp6KCzpzBMIZZdQLIN7d9Ujow==","shasum":"c03be2fd5cba9fd4cf9f4104968779593bfcc1f8","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668661712.tgz","fileCount":5,"unpackedSize":8216765,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICPgXmcmu18FK6AGtQ+N1qTcmAFlUJzbAr++snp2JagcAiAEVi1SSwc354pJnRsIWSUmExVxsRm6BsdKROdF6wO75g=="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjdcO8ACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmpyPhAAkkjQGfRy+QF+L/C5N4tNTBsXpFVFBO6z6bMld1eKIg8TXuS5\r\nt1LdY/EdpvG/GznrhaFTJmGP2FIYNNBZWxpCO7d59g0zMpbr3KLCvcgXCNwz\r\nm6+0374Aat2Ndz1A5z+JMXC5Zwo+SPPqRy7BzOy6WcJUfLNMaJNHjeHNGcYw\r\n3giROk6gZZ70UV6zJEw9G0rskJn/dAJccBbl3XHgiIBf+LOHOl/OnDzrsoDZ\r\nZ8A2hle++z/Y+uloC/AUprD+kUInjPuQthbeaCCMc10HgT6iK7eFHdQaCf1O\r\nXzcrDdBg9RQE0ftyPmTGEzEt0wX75cwfHUBHB6oH0QEdu/DXZfPPQkq7EnQh\r\nvjDBPiuzNfRFD3fXsFjTgrjSKyd/1oB5Ly5MRWjIa/J4ff3vszSuFL5a5rOF\r\nODcns57hsJxvpOX27lAPVqwknHvtfetSsXscdL9Wq+A8UOgYuUSk5fc7vJh1\r\nBOflBntaBE+dS6mZoLjCdsJky7bw2OABWA3kOmNyF9w/B7qu+W5F1nxnqmiu\r\navqyxapSSrZVsh6vtNhqkmJJqXQx/eu7f8j7+vL2KryTQXJfugMap7WEjOL7\r\nr9hXnnZyqtt3LI/jNYCBKvfIeosOv+8zfbvsaG0klXtuaRkABk4A2YrFUwx0\r\nwx/PpUcROclDOJM8DStBU2F/vSkzpsSZPuU=\r\n=2N/i\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668661712_1668662204304_0.30779188720409456"},"_hasShrinkwrap":false},"0.1.0-alpha-1668661712-patch-1":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1668661712-patch-1","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"gitHead":"b1635232e098240a94d38cccf4f8d8bb38508eda","_id":"@mediapipe/tasks-vision@0.1.0-alpha-1668661712-patch-1","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-aokPPO9jUTX3BDd6l4Puro6mmhKnWGDoFJBR7TSvzeYgFoTUcBwUfS0qMNG2bnUJ1VPqFy11NbfKkxAvA07fRQ==","shasum":"803fd4bb7a14c8f4547cc048a1ec54b9a07a5ba9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1668661712-patch-1.tgz","fileCount":5,"unpackedSize":8216769,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDA79FVcAV4R1eBgs8CHmKlIOxqm2Vh0Wh92PTQLZVQ/AIgOPz8Dauy7EyWUkiUv9xljFf8TpNKaGHTz4SeczpaF6U="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjfFdYACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmq7EhAAnusZ9rhTLqQUrlk6sQtsuAqGvlFYCEV7/knbG33uzAtzVWo4\r\n83bbfYq865yYrrbIHKnfWpEB1VNNdYDG1xixL+uP8OLIuR03lL6l86piFMYB\r\n/ESSvPhV0aKTxKmLQtYsFSz8fYGdzyop9QBYhV4Ly7YgD2/27JG5GecfAmXn\r\nINz+qmY0Wybe/RAMGK+79tkq323wvRoRXfChhzYLBUzUdHO7mcL4K6+Vjf88\r\nDEUzBrs1hMeilmK8rnLdBRJp1JLQupYhy2au8GX39tl8hJYhMWr95w7XVgBU\r\nCFH4z5/OULc5uHSlSSk3NF88GY/tIVf3tEaLAnXPZiFIgIMZZyzHL15gRcua\r\nTBwZ2fqBQsfYh9xouzKd4x8J6TR4uKvyUIIbdceVTvk9ZDNINI19i/WQxzqn\r\nubU3rACEHzQEwpdP9SIn4lQfG0V7H11TCUryyOtu/GXAwk2ci9w8Cf3JVLr+\r\n/1+x4Ax4IWLRcm6lEkB5lTtiUps+PMqNRuG5or/XWi3o3dkl1DxWCYlZGYii\r\nFsKMelo/vdrnj/uh8YDh0bcjxUS8D/JQih67BY5LI2cmRPFiIQflZef4WqAu\r\n8L8vz8LnojIiGPYsd5F2sDScrUA79BaWBAKS3/eH/zFGazF9JV/o+qC6zF2A\r\nqN+PP+A7xuEShxEABwP8E0sM7F2tI1u0kDM=\r\n=INg5\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1668661712-patch-1_1669093208058_0.6836903734430431"},"_hasShrinkwrap":false},"0.1.0-alpha-1669754728":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1669754728","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1669754728","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-hvEZR0wFNmnNMOcxZhD05S/vLL8w79zbbyGjMaUTRv7nU5mYhuJTJ10PknblhhquSvpJBtjCfS1hSAJrtjf4yQ==","shasum":"a0c1d5cb0def64e830bdbf5b8e8ec7b574e46b0b","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1669754728.tgz","fileCount":7,"unpackedSize":15749519,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIDQqk64XFuxJJgm2r9WduuakiW7bAnvZbUS0p54DbN1eAiBzI1JvlVZDTN+QXnL+ZfAcS9mYf69LQ5jogWr55eVZIA=="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjhnKgACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmpXrA/8C6KQ5LdPm9f9hJztJ1kcykZrqwz6NvqC1Axyajbp8p4yu/P/\r\nZKRbuXNUZ7Ke83Kp1+pCknee+HFwovnv6b6GbEsEbhWzyJg/TEQ6xAZA5WUt\r\nggX2b2l7z/1GjMcq4zqB2zWu11lzn9IzhBMKad2dSY5Z1vLVLM9COBkHxDka\r\nFW3FrNkeq5xwV2+rT/UZmoK+z8vI/mqr2r7jih6K2bT/PbCAbHi8VDi+cO6F\r\nJ5uK6TEyr/9tBV1doIZXRhtpBYr6q4HywzbldEJRZ9LDYM2pqAyqoR6XW5t4\r\nsKn5EQupZMfOMX6l5sMxWO51xR0vj5BuuP1uXvQ1TXcP21HEe4agqqo0C7/D\r\nImQGrmKKwhI667eMm4WrhXR/utSI08WqMxLKNUjBljIvzlvNizqcnBKXIYro\r\nf9d7SyLSlX2+rJf5z2mP9dYmbX44M+wQX6TEhie/P+ISivCCV7rYDTHMHFQk\r\nFthHLIwkAJj58qARzCP3PR/91eBWNTGnr8TQ4irX4KOcQCNyXoi3UU6YjfE/\r\nWbCf/a7XLE15uqoLqNG42rONvYfvpTG2/vE9GWPVbxkFQBbIEqSms+rnnbvu\r\nc4SklQAXqg4CS5xs0ZTr2rs4kdesLRwYFhmiPat0F0bizuR2LcwuJVS5uBxY\r\ne0VGdSmcrCGoLumuhiYtQcM8sQkogrcOQTg=\r\n=GL3q\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1669754728_1669755551940_0.7945109638888554"},"_hasShrinkwrap":false},"0.1.0-alpha-1670012900":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1670012900","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1670012900","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-0VfbYK37o6wwfT6V3ka6D4Z0hrxIGrvSd7gZ3hWNI7DkwzBnje/Z5JgCclNDum+2Y2RbHqCMGbWHTXuCL+tRYw==","shasum":"362113f40e870f6afeb59642cbfb089daab822f9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1670012900.tgz","fileCount":7,"unpackedSize":15749631,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCOFz19MQoTIceeFOJj8aQe/nWnVZUcTXlVW5c+jvhTzgIgR0R7eT5h/fJf02dh2+uwG8MfbxEYIQjof4KrmPj0A1Q="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjimL9ACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmp/nw/8DCTzS4J6DPjIxsIHO2uldZvilWKmL+p14HtiV6aqVs5npPUD\r\n3lQ4bfO/vRcTZQj+17iL0qMLz9fjSWq2xtxK2fRGuvG7fzShEJDofUXzXcJi\r\nhvqCsKnqkAx1YbOL8ge85hZBoKEug8SjmhntwvFbGGIXB2I3o5dF/z7uj+R6\r\nkmjK+emougs1PfI3uHfrEJ4rHb51Aaqm104z6SDhsi2KZSM6vij8ZDK7K1p7\r\nqU7uZisNnkTLENizHju9DHAwXFvpdO7MBwf706lQGW0ZEl/H0I2xvpgLvkGb\r\nOtWubi6I2C3XwOCbeghcbmf49uI7oAqQ6wyoognbhXjRIMb5yLnfGXQa9Ep3\r\nsiz/1CIP4MnbdJc3EaT/jhreeeAuU6LMH5bWYi2oSjYnTayA0vNdscE2ILaR\r\ni4AQY9uNqk9G4Wckyym0sLIBkPe7beEUJE/3eK+VVHCn1oJlf5z3N1V7XERO\r\nQYNvn5Gw81QuGSknj7CnKV99Nc8V2pkXv1SqDuZAPls335Ve+M/jmUGfaOdk\r\n1OpSdIqMdA/O+mUqpsIrZoQ5IfQ05CSc/3j5lbhewKNzVnefn1vGhGImo9P1\r\noCYA/cS1tZheNgoQnSXFmEQNYTZBsAWHGkE0PKtw+7JM0X6v8dRpDb8MTmcO\r\n7V56by3J4dZQ4Yl+aT3cAE7hK222+GjbqmU=\r\n=ZnOv\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1670012900_1670013693651_0.798842644222951"},"_hasShrinkwrap":false},"0.1.0-alpha-1":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-1","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-1","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-GXN/cdpyo1CX6cO8Q0izudOGqalXGXsffUsKkm9zvW8N+5NIvZVkek7e6huC0G84Iw3qkmtqf4Jfgdh6DJg5Dg==","shasum":"1af8ae4ca39bf3441a158cb1c14c87e273497498","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-1.tgz","fileCount":7,"unpackedSize":15750982,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIFNO3Pl/iZPtFlbX5SF58Rp7M6hCblUe/NXU2L9OEHCCAiEAwI6+66PrKbKaoFe2KJVmtoK9A7gltTpSK2inBMYkFqQ="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjj8XeACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmoFExAAhnibIRtwqsf0MG8FUC6Junj0mCJuFVm8hyTlBUmInoMg6CeB\r\n04DDpU+ujpD2GDKEK7jsTuZp4gFgHSOUqa0TDBvjwf1bDJVCyOevsot1GJ6T\r\nlZsK+6fsduUZHHAg+n39hQsRnUBmVmuteY9wfCb86e6e34JTzBpLAn4PgZQ1\r\nl/tbUGn2IfYuV4mZ9YjdbLTWW0wTMoncb/fktqPf8oahij3vjDV9AmXiv+xR\r\nAB9SZ+W/BpuHF4NkkK1tDwg/PQbpGV7IEVZlFaq2Wz1mPed+mr/H8TECrQDf\r\njbgN/1+h3tLj+HoQgjWZKVDfvzvPEynUBeqGZibKlprja9234ys9EwnaCZ/2\r\ni2sXigqaVz26qU8b6i1++cnGNcV2Qtr+lM5Uqyj0e6NRXx19oYBH/UsLT2gv\r\ny1oy4mkJd55BuBdXb102rslLvLBXUKnRdTbwS88cm7sPAePNJMGUPMSrojcT\r\nc3Iow8RCfYkzmkwgctKg/nj7nksCR9u3ykajoD/YkirpPpHnVr866eAiL9us\r\nmArco/tFDaS79awNNiAgPpinjLPUbog5Uve2jHn2d12uBro1R8zHtO6+0jur\r\n0XIKytkpLYIFsSTEkZ/6L40EIO+XccsOY1M+OkKAhwItyBOlU1wYPdCyx65t\r\nOIUocK1+XWc3Ud4HDrLM0SV61mnuV10OBsc=\r\n=C8gy\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-1_1670366686448_0.41844879450993266"},"_hasShrinkwrap":false},"0.1.0-alpha-2":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-2","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-2","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-zvjWwJ71rQiksJ8f0Z4RJGLelR/R5n+BsSYa0V/PCDIsH4GE6yOaUQNvJGLWuKBApjQsEaScrQpvbMFJtnGbkQ==","shasum":"d9bf4cc9c81f0f84851e8182ea8e7acb20693e9d","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-2.tgz","fileCount":7,"unpackedSize":15691213,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIBK8K6qjRDgSfprFtwIMpJcsLFnF00bG/cM4SWhrRVI2AiEAhXyWF8S/shhvw407el/eXvbbURLBZXykp+6Kb+GZY44="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjvzRgACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmrxFw//cfKEgC6Sd+jNwbLnyAWRYIGqkQ0pi+/uQVxjkEEXkeWPFnbp\r\ntI3ZJ9aD/KHv2SwKXymzP7IKHzVXlY0bw6L5IITNStWjFLHQ9M4Bz7Avy7Cr\r\nTMlmxB0lxN/rAexvf63fDMkoNhzmxs+WssYu6DOLodDnNepfmxSn8bo9QOyw\r\nYK9luWRZsc7ScMxPl5TFtQWwPHD/72ZWzExXhwYsAxEw3KdNojjDpvuKkpUh\r\n//AQli18BIpqRZGd5VL8IRddDJ04uohQOIOrYLCeqIW0InAckhbuBlVpCj4L\r\nz4u25WRmYAnLD6THvRxx9nkA5KuCQPvb2iTiIVYeaWuQTAp+IgU1HyMWbeU/\r\nn3pZl+TwI8ESB2Bu0eQY/kYHU8rRz6sf5OSM9iTVXsf+dHoihSr9JXEcNtGC\r\neCB3k3VrUi4LCBx+8y0wK2xjL5CzO+pes3bsE3TGpMyh4N48BC85Bt3zso78\r\nyckwUWsxOfR0RaiPLSp/4FptYIzihiiatL19pX7UfZYYpxSrMPudM7NH86Nm\r\n3XQ/0/6Nndad+2mdF6T7g0x4dbHgpljqJgCk1UiXo42pwg6h038lbLPGdjqJ\r\nF/x/zaCJxabiwag7bU0783YtSQL/fsSGZNXY64LlS+mb7aoc0Hlw8/OWKV0A\r\n7dqqf8wr31jzFVHXx1jIaGMLqC3x7h9BIAI=\r\n=Jd6/\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-2_1673475168606_0.25623664633107124"},"_hasShrinkwrap":false},"0.1.0-alpha-3":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-3","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-3","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-87L5bHuICdnJNmsuBXlK9HD7x1c2xH1+Q3PD7UHOARAc06d61qZeHXEboVDODC3MiE82Wuc7tF9GiWycqFYfQQ==","shasum":"20679372c7af1c5a3137593f1cc50c0022e55fc3","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-3.tgz","fileCount":8,"unpackedSize":15956148,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDMlUEO8QhJ6eaWgorIU3RyGq2ekmz+sYmWAodwnYG5KwIhAP2JhYDmbZ2kpRQG0kHWuFJY6z9cj9j3gUruclm4YFt/"}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJjyBtLACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmrhtQ//bOnw9Q373P/2MGdILmSJ1rthx50BjLSnGFhRiZZlqf8K1NTL\r\n1HrFZF06EjOfsG3VbZeCjR/oOmL/j4scU5nbY6rDakux5vuDFAm/fZy2QMFv\r\nbRLvHswJ4pTpG6Ssrt7VO9Vn8v7+IKk489F8agoD9Jo0tolcL1XpgEh7Bg43\r\nCWacCqCcaX2IXNBR+tqf1lEBTqXoota6efiNMJg0aFUNRGe45G/KvLkIBF+n\r\n9D+sDUwpNxg73ljiTaZ0YHGfpM8cVIdOnbuDiRk/AMaUob4WcPK1X12wfZqX\r\n5EHlGrL4VFoNsL2xvs4twf+aykND1SxX+F4QU3LxEq0oqfQt3qAt7wpNCpzl\r\nQIsE/qDikeI7EJ12Mkz8MuIAsDYCz4c+HfKX7qbjtmyqKukZsG83EszP6jTG\r\ncGr7soVVBuTYLcF5hiqZO2RN6yw1j3pP3+AvuCOZHS8cbDIskhsLbpaukwOP\r\nt7vNHXKM4RL6RC5qzj6bm/1bNJmHORSZG/XEdVVu4zYkKVaWWxUQP8rKNiw9\r\n/T8WZD6MExtuyQXJP12MD3mfJ5mUlAVeT9WKsZNirwarC1bIhdv1m8HsbEo3\r\n6YzfuygN8vXeBfS6ubD/5krg3tpsHqSYfCP4wUp7dsng6p+lklCzDrjP1kkZ\r\nKVoTZfjbLHWm4xnNPSJONy9fQ8AfQTMlJ0w=\r\n=FrXn\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-3_1674058571309_0.07300144150320786"},"_hasShrinkwrap":false},"0.1.0-alpha-4":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-4","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-4","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-lfTlSJYMO7SD8LwJA9rozlljxey/g4RaYEJWXCHwVCQhRS3Mg2NwRnaKFmbnziyZeDiJEXiKe44Q1LkHNHEoZg==","shasum":"6de18ee879fc63d26345d0e0f7c88404cdef59e8","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-4.tgz","fileCount":8,"unpackedSize":17458736,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQChtELqhS+jhxpW6edpiLBiCHOWDFn3/Saa7E8Lw3/+OwIhAKWAEB9ecjQxMYUbspbv0cO/1R+l1PqoY7uf0eR0l9Ob"}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJj4oaxACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmqQjw//eqH3XGScfCmNgEaBroc6+plqP1xEfCVVnVx9ec5NJLH5M4ip\r\n/xOfu89e8ld/whFEeI9ytflKp+Va7LsQDnpvJ0oa3p8bbchhhYEl93wO1akY\r\nYWDRxXNdh+OulcbJpczO+TfT6LqwI7U5cA55r8QZxJGYIJo/AnLWUyBuiK5K\r\n2OVViFUMCYjVcZPiod7ZmwQWB2gmcbxiAqU4NtSXxSRHX7ppXZRs/qb8/n7T\r\noMsG7q3OyWJXmmxMIMERY8n2WJzeQIub+2xLGDbbV6pVYq7iCX4ZZ7Z1VSGo\r\nTcihL7mBdCoh6oj0d6/WJfl4bG21kO50bfnA0CBMEU1LIxMxjPpDv1a5MZBZ\r\n9XpqzpIbA1uUZiSJWaoqDpCFlsiPjMbIyE9GNQt43gDB6AVeS8bdA3Ma2g+C\r\nOJ9FNBIzXpKPDDqMzclLcj4tYTx14Xm0o5SEzuvroe5t1voncoOV0PkRVNVJ\r\nwwT5JxFt0qdHWz6QP7XI5rE168FhXePBMk/CcM2AjeyRG5fPsjvTRzchPbWc\r\nm0c0ZG+t0jq7lsDo/tzQXgWjD+eT7AxoNcpVW2yP2WxC9sYZxCyM4GPCfYjL\r\nDLeK70p7Ai0wUIuqT30G1q/NVRnz7ZWFMcIW4PXU/O0JrtbGcEExSxiY1J3J\r\nBiO93xrgnWY4Uv3sKeQ4DN4OJAx2qYBQHNc=\r\n=DSDq\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-4_1675790001651_0.5020879284807718"},"_hasShrinkwrap":false},"0.1.0-alpha-5":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-5","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-5","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-IHWLX89woNuozZuCmVmTsCB/B2Jxgy52UuUCYqhiq0Dk/Fss4An6N0HnozFoOsfGS+z7fzpGVPFDgW+qv2budA==","shasum":"780366172c6aa64420ec347e0f94c087d86117eb","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-5.tgz","fileCount":8,"unpackedSize":17958265,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDmz/hldPlRXQxfULFGlUSMbcA0ZTz9KK+C+7Lw4JiqXQIhAOcIMTSr0aSEtxpQEBiC9k+y/whmuM/cRYdj7shtsBMF"}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkHJwpACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmo6hQ//Vh0Tz+lNB4C6kYW+wl5Fj8U6gKsgRu30QzB+LV+0H1+gGIoc\r\n5MvhBJOZunx2wsWluXDd22FGAGJgMTLlyRHFa/Fy5SWhvTgapXdiLJEaa/cb\r\nTkAqIArVDVEK30KdOYbXNbLESUm6NS5gjhibYoDfxUXmabsYAK62zH2my4Sb\r\nueErFDm+Z1157SxhAp1K02LKeaFvIdShj5ZLTgjj3cLVxGPrN9UT0IKhUTb8\r\nyQynTQsx5G4iYvmGtmO9/xbgM0/55zvZEnK6PwUCII54hod+8Jk9TdARFuFz\r\nYM43voodYiKM6r6tmgQgMOqEJ5dLaIT4jKZSkz4P3HgMg/3s25CDLS15w9eo\r\nSAY/IrcGKZFh7LxkXZ6H4yFeaovyTaaJh+WhR7o1w0nMZakfiEWrImmhxx4Y\r\ncESBERAIMm92vy/w4AVDr3Z3oaCY7twd3BRKyM8/G7COXaN0jicPcMKoD5PV\r\nSR7/GDBu2OSKTZ2So3vnS1aRI8PySXWjpHd4MapkTCI/+chnxXBLy8E4yzhF\r\noXD3D5RTQkY61/hhEOoOl9qwckaBUYfcY1eFgUaqOgdcsi2dm15SX1D4eIUi\r\nKpm+WXZbq2WhcGE8IqmDV8ab60XF1PCT/z/b8a6OvM/Xw+5KNZ2LK3IK3Utn\r\n1TddtjHLnf/xHHvz2wUYm9OVVlQ8V9nv6jQ=\r\n=8FOa\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-5_1679596585284_0.27765438475162485"},"_hasShrinkwrap":false},"0.1.0-alpha-6":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-6","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-6","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-B3osNnyfOD6dUjYnOKeICTFXtowK6GwxyWC4EN6tk0M3E8CkfmLra1/9l4swlPx1be1oAnt9YbUC845uEuc+Sw==","shasum":"46d4f40bdef6d32e40b8e8dc279da44b7147da4f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-6.tgz","fileCount":8,"unpackedSize":18465091,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDtQASKc25yYUU9zuXgS+kVjEoZMMRtB+cESLKWi7havgIgdvZjtKispdwV6dbA6R4mO8FmVCuZH/zIYfMnUe99DmU="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkIc3SACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmqz8RAAhX7465+3xFRV7xcUEudcrZ79i93RPPyowZXlS7e/Lp2RcFFR\r\nFR0xq8mO5ccSIhi9sVER1aX9gvGcuApZ8ckzJLDD2M0eyg5gMYencoU6rwQW\r\nX6GSsk8hpGVTXsDTrhsQlkwjrdMGeCjVYD1J9B6J3ULo2s2HZl2wdrM5LtZ3\r\nAJRp60BnbpwyWrqjw4aO0wF7in0090nu+dbY5B2ZaqnL0RarZeo0jOiJK+lf\r\npWFWlRmMfNOw7kTq0zeA7C7dFgymTfnrujD0v9l2zuIB3XkAa5Rfjwac4Xtw\r\nI0mO+TibafSTjRlsR32kvUkYonLuNWNm9iUb3FP0HaEXrNcO+Kb6mZ+xG//0\r\nThNvmbJeWhhDF5Mctsoqg5iI9jxz691Ee9YZAHJS5/EOeZ3AecBr1ubwll+e\r\n+C71IQdFa7xJI44jPi8LRO2tWi6c7/KtST+j7STdz54cuT/ddAdhk3AUh0x9\r\nHPzVWCAxpWwQGdsnzPsJSNzf5/gXuOAqoY6Rct7LzXRu8Y2IrsNrYyvgdVZc\r\nZ5Xeql9IuCRplh6px9pSTV50SSKyn2dP/r5hkUfN4o4VdQ8KeMuoxfyZ3sGs\r\nSC5p/WkVTaMLaOVGViv13xdW5F9mPUYj8vG0g07PN4OWqUWHAR0WB1YEHv/z\r\nmi31lP5aR33+bWWdg6QYonr5ePxcq/vytC8=\r\n=PUNs\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-6_1679936978146_0.27432907031569886"},"_hasShrinkwrap":false},"0.1.0-alpha-7":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-7","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-7","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-Ct+yEd1OU1W5MKDtmtujT3jTxFJRTJI4k6j1rjoBDJnlpgvqlvS+f4hKwnc9Ypzwwyjm3ehZ9kMWW1Lc7qLalg==","shasum":"a4b453ec23d72acc402c3ec3b55235d44493e641","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-7.tgz","fileCount":8,"unpackedSize":18471185,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCID/kidgxHrMemwVCWl/PFCrkrApTir4YYj3EjwnVPb2tAiEA0QdK22jn6uyhrT2TWTynXz3Mk/NbRYLRllg2GDf3p/k="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkIllXACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmp1eA//ZZ1batWNFqZHVYgaRhnNhh8u94shwa8jOF3mNqog+dfY3l2L\r\npLe5usncfPL1wKhNiL4bMYvMs4ModZ9tD5Ma4HDvVwRVth0t/UmdZl9uHoTE\r\n/lFxPd2irWuBra8Bd0SE4S+MxADQM4hqQj1Py/L06Kxjp9ulIvKL1S21xyIP\r\nYskKOPRztdGZmmWNrPRHzQ8JeV3wNxeKOJmGfSTh5jLK/5gsxKLKv0x+SdN9\r\noiVHKq3XmNzRNPcUJ7sj/Q54C1jQVp5ojRMDMu/GyHNeIeVUfBEIxTBbxNEp\r\nK0YzaWQWhSZOiWKrtdvKSbw0vP6OHMdh1NnI9OCPMHm2LU6nF3Kv5414T+uz\r\nBGIRmn+Gf6REl1UE0grDUqX3inLOE9ebYoy3UQpcGpsrIv9Ejk6WS7r6B6gK\r\nWYk2lEyyMvXee4CCPceduw03bDDXB/Ekd/75lKNuY5PaxDAoGwE9WJecCmUO\r\nK5zStN7KdEQdo7N6JZS+CjPbkVDJnqKnO/MXUN1Guk76HyF5Tjt/DYlua1rq\r\nmrbt+emBJP4VjbNrud3oOQBDFAR6OUqD98AOJAmQRSpxA/CmuTVu+BI6KKzY\r\nwnAZ7sME5PHysqPr+jzGQPX5pRhWnU9dVv5rm8nR+qIUGxzRqtdf4icyipOc\r\n9dQtAU8NqGrx+56v0N7rcEaaOz9sNPFSZWM=\r\n=wxy3\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-7_1679972694898_0.8169910239980407"},"_hasShrinkwrap":false},"0.1.0-alpha-8":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-8","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-8","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-7vpxw5hazcAV58lelLwmEXbj+H3JgZ55gmgNJakeON6hMN4/MK5tyfN96QSyrMmSkbH4/u8Eb4ghIEOwwq6+qQ==","shasum":"c06e01b6212cc331588d959d71ddd90e9f420a45","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-8.tgz","fileCount":8,"unpackedSize":18624119,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIAEDtLees8H2Bd1zu3f8ZZG5CqE0A7/U0BdUVQVWL0jqAiBgvBA8Y10VWY73FW0Q7FgQylopgR/LOanJqZV2K41cxw=="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkLxoWACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmoM5hAAnlAlaX0vJ10/nQ4x5pPKil0ujteyC0O8J4+x1ekIBFuOTGeB\r\nVr9x2GKY3aSyRRfLfjAqsZMSIeAYRndEPVM1125sPlMrVYi62V721UksTyCl\r\nXiWva4El+nAFofRxZrLW+KHVZ97+BWwHaPs/JzO82QaYwzKWYu0by13JhA9R\r\nrIh33Pn5ULYiQSupCWFUa66JiDY3VRpXZYxYDzmfK25wngp/tIs0Km9cariA\r\nbJoT4AtyJ3M4j/S6c6eAy+njqVonhl32ZHwn9pUuBzeCKa1NwBy7nBL45TwE\r\n/cREGhluQcC+1Tlni8RG6Py+hLmYWgm2MWzOZFTsSrS/vTFlj61BzZ4RIN9n\r\ni3rGisr25mHAOvzX66YrYFJt5+3ODX+QulBO24O0ZGRSnZ4xJVeC6uUo4fGP\r\ni/5ztP+XaEj34L61mCIQX9b/pnKI/sk0VJMlwzaqEsbnxNF4XTzxUdI0qPI6\r\n7ZhZml1own3lGAfFitX/LUuB91zez2E+p256LI67OlMgUGOyrkzfIzZGTgW9\r\nEy3dVQ35XfKd1p6tciEYjw+TGnwOKjtW6Cgv0iOmmrSKZY9KF3+Dn7s7E8fr\r\nYkLWtEDXdQQUqt+lVHTLQMSpE6Lx7L3yRF4o3b0qRWCdQTy+uD+v8DIhTu86\r\nTOVIZMOOJr5tEg+N+myw5G2+WRdjU8SvV24=\r\n=yoJm\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-8_1680808470163_0.902732053342342"},"_hasShrinkwrap":false},"0.1.0-alpha-9":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-9","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-9","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-hpgY13d3zwbKEyEEG03m1rpEYM56CGPcMGgHwveZ4+SfDjmMLaev14bvlVpog51UNDE7abJTRL6Q4OtIJsSxXQ==","shasum":"b92cf6266d242c2db35128702bba259b5dd807d8","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-9.tgz","fileCount":8,"unpackedSize":18691174,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDVdYYWSOCYsyjaGlXyP7hjlWETXIVfQsuE3ucOCHquTgIgCdtbWHXHkdAXNN9F7HQ2zl7U0hjBZEYPAGc6EW/ZqdM="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkNbWJACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmpESg/+N3u/0U7bmv499MDlVYNcsFdeSYPz/daYx2bm4lF7L5Ch6Pf2\r\nbJu9qfi7dMpLw5sq52FZC/yNZ3hdOpGEL5lNxuPOnrPn9xaaH6KI/EGtcdRO\r\nXl8H136HOrVXbyRnUc1MpQ8EUHllJur10B9np7JMZBRFgJFeTeUJI8cSkFiJ\r\n5iTj2/GFBA7N7PoVWgjzK5sESKOsv9r6KAECzq33NlLV6GpHiuevLIDF608H\r\n/UHeaX/rNiXRHIoB+0eOYaG23jw1/fvkU7MFK9C50WoV+ckgZ9mMe+3RYtun\r\nPvzCC/k/8t9sFoAGqXYYlY3hhJLAoz3NcFx6+j4n7Ntw6b2cdPJKx4WRAmq0\r\nd37kNAKvutJ9l797b3/7CEjZvEGYBrWbBX9V76lDwas6BgWEbydnt/9Zh0rr\r\nhMD4aqfVyoUtEDOErPoV2UZwmAmZwelUMYWnEfwzH5PZrY2RLemXOSErkClc\r\n+OHCBtNDs32U+1wTcf5MYrA5pUm9m6SIl+QGxVwxQxLiigXdytu7RLzYLnJU\r\nfLOtSgBZ/3ISxVGt+yXenKedOD1rCu0zmo11mbJsqAxdReh7wDmftQT9WeB9\r\nz4uN8ah4xuFRjWSZAKNwaqiluJhIrGl5VpnaHRy9tVaKHH6wO9y1/RY5EgQ8\r\nTBuerAbJ1LLuvzN6faDMKlI/s0PLtvY+ndI=\r\n=Zw4m\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-9_1681241481293_0.549425343696353"},"_hasShrinkwrap":false},"0.1.0-alpha-10":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-10","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-10","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-dvhUDUqzKHqi0puPIlqvHkfADed0cC8SYBLPvTvg8RjyKmG+64//jXmf4pXHJeJmKU7HNHnVdERVLYqMfadGwQ==","shasum":"723cac3c164b9a1c6cd7ed13d786550389591d84","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-10.tgz","fileCount":8,"unpackedSize":18714497,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIAFGKHqtiADZEuwVXP2ED5iOithOPGPLwMJykUtu7/jXAiEA2HWrfGCqnpOUsni/zaPsggUbl8+qp+qdp7kGs9Vb9kA="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkOCXTACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmpgSRAAhfaxJb7VMyxhE3pztPUZiSJcTd17gx5VYu4yTFEv9TakeDlg\r\ndOIEapteCHzdmbI1pIoRuyMOCH3TwvBNeb9uKeg5oK3HEE1WZTIXku3zJBbL\r\neYTcKa+FH/HmPaHuJvp44S++I5t+VGeypO5b21h9ghzQJYbZK3fWqPBxRSgl\r\n3bbIRMxx0wGMTTMUdQG60cU4dqZCXI4R3bqy8eBTLt2mCES/tcXiPth/C4rT\r\nwndvGEympF/BxO9Mq91x0NAR6RYGMSGQC3F9jc2BqXUSyBlmETBhlwckeNx6\r\nf4/1RKiEux1gMqvwGaQQx7PL3LAX7m2SyuAy1tM4Ww2EW35BWVIcB/1ZOvpc\r\nB0V4Z3WDs/CbcwnMAnGxzKT39AuYsk4C9RycQkPM4KmAkUpJrJnNYL6ScPAC\r\njUozVmD841Q5xGOST10j57QkFwkgpG5P+w98kPzSlo9p+NVEU+wo+EOvJSE2\r\nVE1snlBvPTBfZGI5zoMuqOy4CwQSE/kbKyrf06MnNBHrXzDX8rWjzywa6bGn\r\nCNK18ZiNa2oBE6ERu5saOTUFVjyba4gcgJdUDRv76ovExbuKpJS+0Y6D+oBJ\r\nsuFzVOlbBh6u4Ff2hQVU8FN5E81IRK6WjhnmQjbHKVl7b/SztTbsFcaqntlj\r\ndtCpkRcgAqhqjsAd1kVhPDrki9cYaYJHrjE=\r\n=rGvX\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-10_1681401299194_0.5470512015203577"},"_hasShrinkwrap":false},"0.1.0-alpha-11":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-11","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-11","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-LBubJZBdIBqcR+ICOk4dJRI5tV2c71MxasYvTbp7ZZFH538U+dwEEKwQLH9sV0laSXJ/LSxVlpWxCDSK7f+WAg==","shasum":"6a5a2356802c604dc9e0274eb44a74fb35e82fec","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-11.tgz","fileCount":8,"unpackedSize":18714497,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQChsfL5EoImCGfJnxa+iPWSEIj1Ro/8X93Lp0gdbsu5/QIhAJs6eFCojpp0wPM0jHT4AlF9e1tKDsSDOWoTE8Ghbwrq"}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkOXZzACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2VmpWVRAAosv5A8H56G+h5exNlC5PGIY+DM3GYLf1LhRbFUOFi8MRe2ln\r\n3gw/Wc3OXQG60vRen4pLYRDnRVdxdL53R3vI/uz+lZ6GGP9iV5rmcjiK9PWp\r\niKFqVWfF0G4536+FOTDjGuH0Zi68Y+dZcHv7WZbVcbS9OkMR2rxwqVkSJYtz\r\niulVwbl6fm9gD79tVKsGJU+T8mJdgI92WabXSLb6hg0lDbvdngXFXqb2xPSC\r\nGnGfNdCQEGNQz4jLDLFsTPaCZ2lJIDCiKlacBxOzduK5QBytJ6aRwTkzCAGA\r\nNdDOcLzWdbmwO2R0+Vi11D3loDfTPwtwNv5cwNZQhAzWFYZR6y7HnoGKW8ij\r\nFPXDsDVgfH6PC3pB6P3Kdu+eWnUlR8Dp89CEPLJR0PEiPugpO6PFe8Dr8Z4V\r\nEoR2p9zso3VQQ4Kabsy3cbXJwkGk/VUXa0wmvI1ybMzEgzjbDKcKiGwwwDEZ\r\nIaU/nw7F9paRIxey6hQGUs0WvxVfPtYW9MWlNBAykVZhM+taZ/1UniyAaXXB\r\nOWvpWERSMoNmkyVhJFwn4YMK1fSt4t5QckkDhI4dMFfIaB3hV6d+ivwgtTL/\r\n85k5O6DGZXjraQq00h+8ZHlifNkqjZbQhtKa/2KDJKqqVI5qrX+8b7/KSbKr\r\n/eiB7IAoGR5aiMPMi7R9Z2MUy3oXHlozlPg=\r\n=93JR\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-11_1681487474939_0.031915543053571804"},"_hasShrinkwrap":false},"0.1.0-alpha-12":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-12","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-12","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-zVHZdOHusYirebuWHD8bI3h8G9rZlcw8Cg3fyzYS1HkY+mzdgbxrI2VflvGXkvIM4g2WxBKs9pIPXXr33HkGDw==","shasum":"273d978662a7d01dd113bf9b3e73b48dd57318d8","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-12.tgz","fileCount":8,"unpackedSize":18601415,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIGv7gO29rG1Q7th8uKFe0GA4alHu+gdvIt8yIDpVq6mjAiEAyiVzxWon/XJoKTNr81cJtPrnEFVb750p01g+MkAJ9DA="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkPxP/ACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmo+3hAAkMJ/L4aAXRsUFXWrS7NtvlOhXaWbrpXIGszOiMUVSEK2JvzH\r\nGcV4oBn4fPTfLUBHWed6Gnw0/dHfXXFhTeN+5uG1SFdvDFRHfYAbcF5YPNao\r\noNWsDDxwv/0uo5hRxNrLg8ub9T3RfDfSvwBAq9rbnMkp1aTZBoaaySPGmJce\r\nNyn0+hR5WbHPsSE6zy6mVVjpMgcz217VbCBpcDe7kwnH8TD8dOO5P4vbxAbT\r\nGROiXWHZdaxv7kwk1pD9c/+8RmyjqQLg+YgDcRUiNJOeAVaCFbtomOcOmwvj\r\nSws0jPm61E39O62tbeb/Aw4Mkumb6MWYa28UMmKCLei1rCQfBefidHFJuCl2\r\nWwrtbWGz/VwOBGxfJaKL9MHQB6O2O2jFJq6YPJaOUI4qdUOCH+AkxBmmDw59\r\nTflZp6GuwdMT9oR69PUOgkhgIAIQ3ghmdF+wxzZzFU9S8wl2c/iokfTwtC2b\r\nmCGtBH9tQ4mAETnSXn0j+GnSiFXr6A3wh3nJ8W5JOkEde/uJwD5gTd7XHrrf\r\nbWbr9RkrUiahQn9b3aUl8E3kuobj55rKLG2fGp+eyF/U+EHAP5a0xxj1gDmO\r\nwsDqydhm+V1BhFO9jl3gpqBC7vLWctDFq2YvVeITj/t++FyVvzLowmxjcnOp\r\ndjS7aw7kdy1/WgLebCoX4y6wTYloMLkYUjk=\r\n=cYPH\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-12_1681855487513_0.8525609741186657"},"_hasShrinkwrap":false},"0.1.0-alpha-13":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-13","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-13","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-sHZGxeivP4xqy35Q3fHt1JfeVoKJXDl9CtaYEYRkGtmoqhbiXCV2FNsVT7oYsSroIseKhNsSM/Zeje2/BQocKQ==","shasum":"499aff9be544d03fb7c570ddb7a56657c27b984c","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-13.tgz","fileCount":8,"unpackedSize":18593011,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIAFM/Y9AbAhZx0C+dThccPEFIKX3l0EpnyiWHpm77CHFAiEA7Y3SfEtp72nJY3ClG3z/hNiqxkNdWr1tJIY1EkDC1vo="}],"npm-signature":"-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v4.10.10\r\nComment: https://openpgpjs.org\r\n\r\nwsFzBAEBCAAGBQJkSwqtACEJED1NWxICdlZqFiEECWMYAoorWMhJKdjhPU1b\r\nEgJ2Vmo2ow//YWy7iaKTVKWYYNwquENOewOu5GEtI98KqKMcnrED0p+JbgzT\r\nyWcnXj0cXB1o/Q8uU04QaXNuvabn03VbeQkm+weEekV8lp1xB7ydPipmc5NM\r\nd6qvkytbdWJVVCHLTr6YGOcicz3W1jhv4RbqcWBh3RVOtV0HYVFjl7VX809Y\r\nbuxWcP+XvQ/SjZsa3z4sNZlbzzPKp6OOeeQT1HzniI8WsX4Qkfg+9889gXHy\r\ntT1as7Xxq6HJ3tC+0kyiPGiVhfZ8QB0VUmel4kYqsP23WkksqyS1LyVRqVtL\r\n1ACSDpb2Pfn/dgxAAMrl1oPh273FIkGlIWNm2v81kuI7UeSSgmw2/Gn5N/g0\r\nEonSexHhVxuVR2Y+T+QLHDITo/Iuat7iKqOiXC4Re73ZWEGi56og66HeEJvG\r\nLCoSWNpExnSFE122+4jMyeoY5VDjqAcIPn6rCFelDssYfANusD+anz+D9GuD\r\noEGcENkNUvjr23L0WMW+NrALxB+DDu9jEeTd/TDwyRbuGxc045VYugcc/swv\r\n25hgFF+KbPtJRPXDmqCD4TZbc2/kiBG/H6KSm0sNLpbyE0JUKWYU2asNLahZ\r\ntQkr+zzFuBrQ95h45n3yl7CbZDOCnh/O6m6eHbZAMPuvmNzU/gouMv/bNNUf\r\nhrYv661OIMLXgaJB6QybKDFAC3d3YAf1kEI=\r\n=KmKG\r\n-----END PGP SIGNATURE-----\r\n"},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-13_1682639533013_0.12367503998986473"},"_hasShrinkwrap":false},"0.1.0-alpha-14":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-14","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-14","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-YTuG6mblRqfivt1ATczMWP7B2jt4eyHd3i9QD7JJoJ6kwpT9yW+lMXeyncCXIKps+u6ooPTNVBB55L06E1R8wg==","shasum":"e0e9904eca1d9f2f7ac219359b956f59836cad2b","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-14.tgz","fileCount":7,"unpackedSize":18588221,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQC7VSLxLxI4ncnb539DFg2L2uF/wPqpr8dsAaD8usEergIhAMdTihgtwwCZL6ovJaIb9nT5Jo/2+UV0jmencDnqMZfE"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-14_1683588579274_0.6617182079181583"},"_hasShrinkwrap":false},"0.1.0-alpha-15":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-15","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-15","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-jGrAagdpcaJJi5++UyhhTVHzdrfEQYHdvvP6Ukq7Td+aH9Y+GpHj1MwbDMUonSg0tnV029eA1bdYGFMQIwtqew==","shasum":"e55771234dc06189962a4e60cf1ae9f1e5a45b49","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-15.tgz","fileCount":8,"unpackedSize":18690737,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCIpp7ip/6Ar9guGrqyIldwaMqjk3npmh9lw702JnMtEgIgbMxb9JXdQoUpWbMKI0Q5OonF5W78F4TzZ1UgP1+Omhg="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-15_1683667802735_0.237565149078794"},"_hasShrinkwrap":false},"0.1.0-alpha-16":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-16","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-16","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-V+mEbBD+tdq6++E30vudk7BiAOaqJGCkYBjaELGFl0tlW93uKaCfjEGJpndWRNU1+rfUTDLQx2TXCC18z1DOMw==","shasum":"3e887ffaada59579857cd8ea94e8d9f857af6407","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-16.tgz","fileCount":8,"unpackedSize":18690735,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCKDDLnUWildmf2aAiXN9RNDUqCwPwLwVdEAAheEbW7ugIgQMLohJyxeMgMKlFb4tsy1+4BERzY1RVCNPTUQfH+0/E="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-16_1683669259619_0.7344002388347308"},"_hasShrinkwrap":false},"0.1.0-alpha-17":{"name":"@mediapipe/tasks-vision","version":"0.1.0-alpha-17","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.1.0-alpha-17","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-3T51Uw6JraPk2qBKWSKHCQbdrfEMUKotHyrIiRNz7fS6I7N26BqRZ53O/676PZEaMRmxB23CX7p7McInGax+SQ==","shasum":"d1195ebce1728fb52dea6dd420ddd00ac7780400","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.1.0-alpha-17.tgz","fileCount":8,"unpackedSize":18691702,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIA0WMgndAxPviIuQO6fAKuq8JEpvW2dsu6zNfXrent/DAiEA8rCLzc7IPnlBmgJ4N5NwOmiZDsVRBa3Q0CzJIGIK//M="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.1.0-alpha-17_1683689280397_0.4425237232142347"},"_hasShrinkwrap":false},"0.10.0":{"name":"@mediapipe/tasks-vision","version":"0.10.0","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.0","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-l7Sqdw9EgO758tLrt+jDqqKnYKjeOFgzC9MRcE4qZnh/XG/o7JBacEF4cAzes+2wsElRCVoVGf8ETllIqgBzWA==","shasum":"d95a816f66889dcb15545636ac7fc78588c1d705","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.0.tgz","fileCount":8,"unpackedSize":18691694,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCk3la+h63WnZ5JjFipOQtji0AMrX2ehVOQsPAS3QtYFAIgbjBL+wkEuGKhgopeuCYSTZQ5ZftJdO44KZu+K4OPYno="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.0_1683730333687_0.3591313183404654"},"_hasShrinkwrap":false},"0.10.1":{"name":"@mediapipe/tasks-vision","version":"0.10.1","description":"MediaPipe Vision Tasks","main":"vision_bundle.js","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.1","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-/zIKjOAIABx+KVfqe8hA6X2pxBGsBYlEtvD7/gpXecvzKefo/JQO6XaggmJul7+noaqiPYM0CVGZxmFJ2oTdSQ==","shasum":"68047459352019cc141dc9c1d15c05b8ab689423","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.1.tgz","fileCount":8,"unpackedSize":18229135,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDymW9JjJ0DnyW6kluEWhQVBH4W9ASpwZaCACYq3kb0gAIhAOLhSHCRI9aJcpEoNMgGSpS7g5hmyyFtx3sUqDvQoI9L"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.1_1685991069934_0.8497557471194139"},"_hasShrinkwrap":false},"0.10.2-rc1":{"name":"@mediapipe/tasks-vision","version":"0.10.2-rc1","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.2-rc1","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-3ZL1p/ktq7rLMyADzhfa88KdM+yxn6DsN3EGF7UQBZBF5+NaAvQq8H8kTh3IKgW4lQVPvGT5IWzK8CHCo7yVgg==","shasum":"936b000197a5201d38fe0085a8d029fbaaa26c2c","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.2-rc1.tgz","fileCount":9,"unpackedSize":25885447,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEfWdFGQbjRFBpzINxwAR++pJbDUOceRm7cCJTyh932TAiAC7jY9ypl36cuSV94cskfwWwhGcquux9QKhA2o1tW4tg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.2-rc1_1686592907670_0.9545758838320544"},"_hasShrinkwrap":false},"0.10.2-rc2":{"name":"@mediapipe/tasks-vision","version":"0.10.2-rc2","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.2-rc2","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-b9ar6TEUo8I07n/jXSuKDu5HgzkDah9pe4H8BYpcubhCEahlfDD5ixE+9SQyJM4HXHXdF9nN/wRQT7rEnLz7Gg==","shasum":"e3fa5d84d58b9031a0e975d1e5ef8eb8e4a6fc11","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.2-rc2.tgz","fileCount":11,"unpackedSize":26383498,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIEdlmgqhSTPbwWPPZqz96pdLioMdCT0+e2VimbkLVpyxAiEA2NYsOwPoP6O8L7OehlfBW67h4az44Ox2Ww6lioHwtEc="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.2-rc2_1686594967034_0.6545940976162428"},"_hasShrinkwrap":false},"0.10.2":{"name":"@mediapipe/tasks-vision","version":"0.10.2","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.2","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-d8Q9uRK89ZRWmED2JLI9/blpJcfdbh0iEUuMo8TgkMzNfQBY1/GC0FEJWrairTwHkxIf6Oud1vFBP+aHicWqJA==","shasum":"eae193cf4a5c57baf2b235decde288b5152ee433","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.2.tgz","fileCount":11,"unpackedSize":26547042,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIFhmDBViXTJUUyN5OAt5qmLjvEpGRYZm88+wsNaQn8hYAiEAslMndniL/AQS6WvPnuy0r1IKhq2n+FrpBg9IDVq1cBo="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.2_1689009034746_0.7103992633910865"},"_hasShrinkwrap":false},"0.10.3":{"name":"@mediapipe/tasks-vision","version":"0.10.3","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.3","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-q6yPXKGlANzLUc77X1zN+AKLFTiviCYtRXv5SV27GnbUVw0lsy94ybBmsxIMa+pATWIi0GmmtENJt3k0BAQheA==","shasum":"d1465126923df8f03b4a31a231867d284e120961","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.3.tgz","fileCount":11,"unpackedSize":26809865,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIAzKn81wncUwtM54gJVU9gvlzZVd67oS6WWLAWVFyix9AiBynauH8TzyMaOX6GTOSnoNyTkutsZFBJmCD50ipbwQcg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"mgyong","email":"mgyong@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.3_1690913994241_0.9966549186731017"},"_hasShrinkwrap":false},"0.10.4":{"name":"@mediapipe/tasks-vision","version":"0.10.4","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.4","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-KpwgHL2KlrAnjtrLf99ZsglHwyWUJdtF4/LqpNKLRl1bPRH4FE+C7k/w0ZPIK71EH/J/rLBcSez0vbWD4ih88w==","shasum":"9309c007880198c3b9ac07211982a020f7917f7b","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.4.tgz","fileCount":11,"unpackedSize":26809861,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQD3H8WqwXCnO+sf/+/erBm1yfcbzmH2nFLcPevNLORp8gIhAKkQiLeiqRCC/n8hMuJa1pKplke6AtPGlUPFy3UhpcRT"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.4_1692817166571_0.9659608231004946"},"_hasShrinkwrap":false},"0.10.5":{"name":"@mediapipe/tasks-vision","version":"0.10.5","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision_.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.5","_nodeVersion":"16.16.0","_npmVersion":"8.11.0","dist":{"integrity":"sha512-pCLvVEx917KHMYlIP/TqJH0XnO3ryObl5ox2l8cKSFGIWvmT9bKCq+lsD4N89UaslxEkB6ofPLRD2mOm01n1qA==","shasum":"09cfcf873a1056e1e80b9c6fe3b9f2c1836cb1ea","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.5.tgz","fileCount":11,"unpackedSize":19289767,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQC4DoSII8VHhqW1hASe5D6g+1pimEQluC28StrtosAJ7AIhANwahB0uCVN6cGthAi60CwMKWj/purlUyeIISxq+qh/u"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.5_1694709093548_0.11145359719371983"},"_hasShrinkwrap":false},"0.10.6":{"name":"@mediapipe/tasks-vision","version":"0.10.6","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision_.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.6","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-DzWMTI0FIeIPsVqnFKRKFQ3yng9qrtT3YuYkGNVeoob12br4+MVoLFlfkKP36mIAYM9/Vj2SarXCvTA14rdQsQ==","shasum":"f2000eddb8bec0367fbc5f044ff2ecb87e5f38d9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.6.tgz","fileCount":11,"unpackedSize":19020686,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDcHkgWTrUugmYSd5100MsS0v/HTudJcqxWzAHzQB5IRQIgJLhlhRM2YeIxpKZc9Z3lBj1r3i2QD4yzTEqZ9EQQ3qE="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.6_1694809885920_0.5275650173496775"},"_hasShrinkwrap":false},"20230919.0.0":{"name":"@mediapipe/tasks-vision","version":"20230919.0.0","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision_.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@20230919.0.0","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-UO6+4Yf2FvyTeHLy3P2stu3rrsQEa2jcq1EigwMgumg2zVPBiRLWkIcKLFwsDsOrj2OBXhpjevtFt6gllrW+VQ==","shasum":"4d0a07f0142efe3611641a1cde09278e46e9c7d9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-20230919.0.0.tgz","fileCount":11,"unpackedSize":19014006,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEXR56XIPj6mT5YqGqqEk5/oZrAiOWLEXVSlaNZBthLeAiBVBWU3GneamVugMYEo+Bxs1v55YA4ibUTKPvAlSyJZVg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_20230919.0.0_1695159142997_0.5796908867944142"},"_hasShrinkwrap":false,"deprecated":"this package has been deprecated"},"20230920.0.0":{"name":"@mediapipe/tasks-vision","version":"20230920.0.0","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision_.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@20230920.0.0","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-P0EGItgrOlsgQH9yKXW/n07UpFF7AYzTWgO2HiRxAJosbU10q8b5bo22UtP7OO4C83QUkTUoY7xurybIAHmjpQ==","shasum":"e67e03bd1c89ca8db75cba8ab7594034f01eece0","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-20230920.0.0.tgz","fileCount":11,"unpackedSize":19014006,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIFFAH+YbN4Mi7//DZahD+z1vGPIjoIT1cXU1/2L0PWbmAiB/webx+nJUB2qytiowexUDjSXpmbxOexgc6cd3CZ2v0Q=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_20230920.0.0_1695212262888_0.2975272437920897"},"_hasShrinkwrap":false,"deprecated":"this package has been deprecatedccccccc"},"0.0.0-nightly-20230920":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230920","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision_.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230920","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-Lzw6+vh1CRSn6SEaHm3WhLtMinVtbB6YGZzUL9wzwHfjHIAGCx1pxoxgvfaDa6DR/pGrCzIS7uD8neuuz3L8Ag==","shasum":"611c0ae5ba8166860464a31e0a38ec3b1be53e27","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230920.tgz","fileCount":11,"unpackedSize":19014016,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDMvZWCIryzqyfMm2Nj9KZVrxQEnyKwLCd2zzi/wAt+UQIhALe+UUV7ru/FdxGhYOhMQmRoXnNC1xvtHHz+ITn3X/EE"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230920_1695231946042_0.44319283850647073"},"_hasShrinkwrap":false},"0.0.0-nightly-20230921":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230921","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision_.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230921","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-ih9LT1vpZmCsPlDyMEp9zmtezIKeZahw8p1jJsFbDcf+IAJ3bgiHd/S4Qjwl6VnqJZNT/XRmxksTG2CzTyUzxg==","shasum":"81ac51d3ce64a49daecf51d7fab75a784a5c96a6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230921.tgz","fileCount":11,"unpackedSize":19014132,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDg7ywVQmLYYVgu0k9MLjM36IJkrXxCRkF64JHJ2TqWcwIgKXvoVfhPPSuh+X1jKObQO2/0pEK63k4uAZHqOAmQZuA="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230921_1695298589410_0.4076590521127126"},"_hasShrinkwrap":false},"0.0.0-nightly-20230922":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230922","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision_.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230922","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-SBN0WOzC+JV3QPNOP1FWwifjeHPy6LqvS1vF548QzzWaCyXNm5f1IuxDAACiFm0ctd+WQxwDiYsXOme3Q29lRA==","shasum":"b85fa6a064e327b85c6933c6695c0625b21b0f77","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230922.tgz","fileCount":11,"unpackedSize":19014712,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIFZfDHoUr3JAbM+q8rnHAvxHoL9GzYMMdV1b/lysQEOCAiEA7TwLpatZ7pyebBdD9Bysrh8AjkCGXwkV+o6TpF3BAVc="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230922_1695357975331_0.5637450770617058"},"_hasShrinkwrap":false},"0.0.0-nightly-20230923":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230923","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230923","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-eqgq6qoeav4Y9QNQq7CgLRcIZCi0HIqpUNGcepudPPkLGtX5nOMTxLfx/xN1MTMT464hC1sgN9gDTbH7dqz/TQ==","shasum":"2562c50a444806bb1cb77923b05b996ca007b036","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230923.tgz","fileCount":11,"unpackedSize":19014711,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDThifOztuoGrIM1u4trt8+gNyKxNEYkUxxggXBpS3VwQIge4Y9uUQfBhkpeB7DSCQqoVdqjvLxUdaaTuqHip3GGbM="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230923_1695471369349_0.9511505509805727"},"_hasShrinkwrap":false},"0.0.0-nightly-20230924":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230924","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230924","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-Jy/GuW3HggmkYxozz44rNsYZ6ZmZt6QGLNxex2W59KPGyJANHNKctt/Q7CZ3KK0pWT2dYgg0oeRaMQG+68cKQg==","shasum":"b9acc91b75a888be26ea7f5c12f3e983d5e050e6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230924.tgz","fileCount":11,"unpackedSize":19014711,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDNZY1TQPAWHLRP5Nz3ghEmkHC/CVE+xtZ8gBiKOhwWKgIhAO0UEbtjw4nv5hmBpivjfKj5HF1jjTgJu6vcmab8ATji"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230924_1695557697326_0.4692673229882205"},"_hasShrinkwrap":false},"0.0.0-nightly-20230925":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230925","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230925","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-thQXfcCX60Imps8vu9zTO8CBNw/fzHrcV00G49PP5JzVkCRi+bSCyKZHcfdZgTGGSMBkhsFbWCnpVEbkdVrEmQ==","shasum":"c56ccfaffcb797e8aade81d59d694962fbf079aa","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230925.tgz","fileCount":11,"unpackedSize":19014711,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIA3mDB955qVj7u2o0INmV3fxEAD795f5APf/pUDQy8wuAiBbtyXQ0ItbZJtc5k7XsJP+aK3BHep4c0fHHyRu/3EHkw=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230925_1695644692366_0.11594958925851406"},"_hasShrinkwrap":false},"0.0.0-nightly-20230926":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230926","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230926","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-dLqFgbEDw1Z3ZWGtSF+wYR17UPWIL9RR1lrqgQTZdMtyHAsvV8870QRnJXrlOM+hPV3Bg6wAAk5EeEE9/gTdiw==","shasum":"63edee6369a15b5cd7ffcb143d360ac233a7a674","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230926.tgz","fileCount":11,"unpackedSize":19014711,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCgciFG2RpvXbeCbnOPDE2wUXflA2u9YfjsfHZZcm2EAwIgP4iqwBQ4dq76ZyVAPAYB7VE4BWDaCCGPUBR1D/kwx+E="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230926_1695750885419_0.7129111020463466"},"_hasShrinkwrap":false},"0.0.0-nightly-20230927":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230927","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230927","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-lmfjjpZkx1lUlQbAIm/vaw0iZiLrTI6GrDz53BZVzuFyNNah10SyMX+Hj7LD5OBb2ulXiCvK+nGd8SlxET2BCg==","shasum":"9efa99dd2b309a41355aed71d29e410a3b3be1e8","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230927.tgz","fileCount":11,"unpackedSize":19014711,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIERwqjwr0556vPqMhgtR8yv2hAv9VCXf8DH7FAaX0CbIAiAGKEI37UJspMrJ6resCJLyXZBoBMz0Sz/TvuiFJS1x3g=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230927_1695817269209_0.7237116883946035"},"_hasShrinkwrap":false},"0.0.0-nightly-20230928":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230928","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230928","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-BiDfTbL03n9AzlKRtRjnunSkPqqDCmMwLdphG2XMT/qzlOiRNQUDjMQdc+mrpewXS+OsYuVU1T91WbhVoJxINA==","shasum":"9e043a2049fd4ae7ae6d004073dbaaa08f4d0160","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230928.tgz","fileCount":11,"unpackedSize":19014957,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQC0CtJZWSgrz3y99/2akyW4O6Dzz2sC9ddW3E2qOpN9kAIgUEJxUHz+gLbXiXpRtLvdSME+D09HfPhL2JiLT88H7qs="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230928_1695875397300_0.9078376316874024"},"_hasShrinkwrap":false},"0.0.0-nightly-20230929":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230929","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230929","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-pa78y/YmXHXveAYTKOxu2N1sgizlmNYYHQ/v/N0VYMrdjC80SSXdlhsR6WXEvzfJvnb9CDjtD4vGsJL8kccstA==","shasum":"8bd608f882e1a51e9ff37d204caf32cc2fa193ed","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230929.tgz","fileCount":11,"unpackedSize":19016123,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIApGEvW5nIqUnulgVrsEcOQR8/qVn3w3sXa/lTCMv/p/AiAYJVJefOFHJzBI/Xlbkkit49OgddSXAaVM1q/ku03xBQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230929_1695989922147_0.4816047678326907"},"_hasShrinkwrap":false},"0.0.0-nightly-20230930":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20230930","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20230930","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-53Qh9dv2kaSzXkCUh210tCa/NGZaRtUtavQ6QoXUv9DrjfJF61MQSnFNel4Wdzz0WWnU4lbjNrv8n81CWosZIg==","shasum":"7a761b627033175d6141d9fd0edb7b2a0a2451e5","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20230930.tgz","fileCount":11,"unpackedSize":19016207,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIHv2+TczAXZZivEjqOu1NU4s4VruubT6dHWGaUr4w73NAiEA3CS10QOthsAKMNjxfjIniuOnsEn6Jyp6HB/nG9R3pck="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20230930_1696047326135_0.08621959753261321"},"_hasShrinkwrap":false},"0.0.0-nightly-20231001":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231001","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231001","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-tBHJ+JvdM++A3n9DsmsuAGxgU44Z8neWUeuYzBqDjenquSlzS5Tpyvy/lYqBohOniDJQ3JWJ/JKpSKp72Jc6sw==","shasum":"978664b7062edf394b3ff0f0f1822ab07a2b59ca","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231001.tgz","fileCount":11,"unpackedSize":19016207,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIH6deEKa0MIWMuuGpEUZtY+5CKZNL1wLVcnzn6SsR3ByAiBpv4typH/U1NeKyEa9cWUnhwYHJHlWoZd3iTHiCp7dTQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231001_1696162723647_0.7601324282533535"},"_hasShrinkwrap":false},"0.0.0-nightly-20231002":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231002","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231002","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-DSMZSNnV9JJsEKCluO8pgoErXHNul+/EgA5MDHqCGqyLSzQSPyGItSkoLUWQdRIcnyhth3VlA9l+7CKrZIPj8g==","shasum":"aef00621a377c47ff18150b618319a59e69cf28d","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231002.tgz","fileCount":11,"unpackedSize":19016207,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICrK+dVvUFcWISJ4YBn67ZTIBTkMuoiPNuGTJgZPpbpXAiA/sUbAXNQg8KewzzN6wviYRY9M0oVP3Bv+xWBrbBurLQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231002_1696248922088_0.577698888362079"},"_hasShrinkwrap":false},"0.0.0-nightly-20231003":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231003","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231003","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-8ZwCILQhwEs2RkgP1T6E2nvDHVwn8Po62r64POdx02c8hC2pyO8M9XKh+IZbw5obkJoFyDbbA74tqnpXcjx5xQ==","shasum":"11f35e0c17301e2bf37df1b0ab2d6ba0db0203ec","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231003.tgz","fileCount":11,"unpackedSize":19016207,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIBwUjzh7hOfaJ/UtG9ey61usYo0/JygYU27hUFodNClmAiBDlY/lgSbasa7LPLqK3cGJ27UScd7rkH9JT0KvIRDrYQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231003_1696335433116_0.140000805135998"},"_hasShrinkwrap":false},"0.0.0-nightly-20231004":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231004","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231004","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-GZJtI9xYn7McOAa3iZPY/cxUUIkDx3soO7WjttNEOuCme8aIoJsSny1hbdIY8RSyvSne+gPu259ao20OWjzUYw==","shasum":"09440d63615eed26545adfafac9bd4279c0e6d9a","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231004.tgz","fileCount":11,"unpackedSize":19016239,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIBcqC6zR1e0aMuo56FcM0Q6VzLlVHl+dhAzRMX8Hgzw4AiAcvRJEfu9SMF/NjBYvWGwRE2bylbTnK4jhK2XGi4oZzw=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231004_1696395404740_0.08295937513783991"},"_hasShrinkwrap":false},"0.0.0-nightly-20231006":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231006","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231006","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-H2ary6CDfrinChq6OtlWwo/fT9L7Y5D9Wjssvj+6IkJLEzwwobJ2S1j0+i6Dp5AadT6Ey5aXdi137F3u8ixrtw==","shasum":"d7052a4b15c14b77a68ccad9e6d391d9f6d4dbab","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231006.tgz","fileCount":11,"unpackedSize":19011375,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIC2svKGyWjTbyUgcK79BVw7+Pde/PC9srFQgvQCM8fSQAiEA9PwjSWw8Z1txhZHWoVn3/VmZka5SKRo22znZKntqfoc="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231006_1696613304771_0.07045577805993375"},"_hasShrinkwrap":false},"0.0.0-nightly-20231007":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231007","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231007","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-HGkZNpOWR8LQdhqQOE0tEdEg9hjgh66fnE/UFw70pHTlrCefAde4vETM/QXjPQa3nP314K/Ut/+AtrQtM2nt1A==","shasum":"2ccfa94bcfeadb30d17697f6f997a48051134f77","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231007.tgz","fileCount":11,"unpackedSize":19043759,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIGi58SMYXL7jNydCqExq6A04NPrEw77qTzGOp3MOaW7WAiEAkLo4/VY7N4UaSrJpeEXS2m+JsUSA8iXUb/M2/fqa13Y="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231007_1696681056196_0.23138466447992312"},"_hasShrinkwrap":false},"0.0.0-nightly-20231008":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231008","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231008","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-lv/zrzIrRV1rFTJKtFW9bnMoQ/Pyszgx1YdIb4pXXTa7iWQCSlrVMtK/b3QPTTkORXkSWBnn6Zhb55UM8vLgHA==","shasum":"851ffb5fa47e8648c18f165b3a68600d12fd69d1","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231008.tgz","fileCount":11,"unpackedSize":19043759,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDWsRKGFpdNqet9MtBijNePJz6MsjmYPbSqMLdTfq9S+AIgV68mfOxG9nZK1AYLI60d6goJIqhQu2WUfpxX4Q42gPo="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231008_1696767284138_0.7324296215533905"},"_hasShrinkwrap":false},"0.0.0-nightly-20231009":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231009","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231009","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-ejMIRMJWMI3umrmnGRwNob5dd9LX3seL6lX+SVq0i0xrbZNjvTYfLE85HCuzAWSsKrpXRw04hRoWj263vV7pxQ==","shasum":"005f430c63cfaa8d744efaafad8f45da0bd16580","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231009.tgz","fileCount":11,"unpackedSize":19043759,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEDOQ88z/HONLaiGfpE9ZAJCuGx+jTf9tyBjr3DfnLieAiBEXLgzC2FlcC5bdH+IdfU2TdlUqblPKhfdbVWFFXrvGQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231009_1696853796661_0.23239620228197277"},"_hasShrinkwrap":false},"0.10.7":{"name":"@mediapipe/tasks-vision","version":"0.10.7","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.7","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-ojuvZB8Jz8C0MRDV8u/0tWOivmoSUpHkmA93RgYsjOEfGAJ9bs/mzqY2LthbF/Cuu220iw/fzZX4/fProYKsQA==","shasum":"d5c9181c3b93822b0b6bb69e30a61c37389f9748","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.7.tgz","fileCount":11,"unpackedSize":19043743,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIE6hfdC0Lat3+xjZdy4rIJV1Xt67tOx7ymb6TJusLzhRAiB0WLhXnXo46y3LvUdegnecjzn/L6C8Yqa1eQGXBf1BsQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.7_1696883790893_0.05806872926819384"},"_hasShrinkwrap":false},"0.0.0-nightly-20231010":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231010","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231010","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-CLjsXHWGYbz+myNHUrhDzbxms0vrKXH1UVmnKD6P6N0xMSWzsnN2fao+UEzMSdY7JJ6Wbp39NmzNVEBt1bIWJg==","shasum":"3543a8d7d830c4fe951a3f164f2d68a0be92cbc6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231010.tgz","fileCount":11,"unpackedSize":19043791,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIBIWq8ZrCisAC06QEQXqcExTjYj6ko0uYn64ukdXH3WYAiEAuS3JHtVKo5ZEpb4+Cqrk2Mr1U3MpEpGUBbi4TDOrpo8="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231010_1696940124502_0.1241088328803488"},"_hasShrinkwrap":false},"0.0.0-nightly-20231011":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231011","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231011","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-FQT930SM9ziWee3itD7KFJjDEOEA8T1u9aiIyNx9URlZ3Sp7xS/Yx35tIXxHJG4Mdaucfn01oTMeVzA7fYvEcA==","shasum":"c1882489eb855c67fd0a845cf63b01b9434de906","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231011.tgz","fileCount":11,"unpackedSize":19043745,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDu0D4Mn/hVehlMUMgXWNpIbLZkimX28i3L9MXAq7I6gQIgRwsxZFmI/Hs0rY3N29VOv8PB0LL66cGSlLhCml42kMs="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231011_1697026635806_0.5576067872997126"},"_hasShrinkwrap":false},"0.0.0-nightly-20231012":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231012","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231012","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-5+uUiNxfPGU1eI8Yujo/XYyxNQ4OOarPytPdIlpZr/QpwYOWr5aSQdbuKCKb75ohh/0hhiz58U7yO5VRLZCc3w==","shasum":"a6f80066b72621ce99d74a6b792ddd5ce28f7590","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231012.tgz","fileCount":11,"unpackedSize":19063515,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDz6a10bXTpSQ1Yjxv3VQZukyq4TVnuiBwErGbyOsdFTwIgB+SjXt7f4mQcAZclOIyPLvhTZINZJToYbvdU3MUfhCQ="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231012_1697113049856_0.35670289565983726"},"_hasShrinkwrap":false},"0.0.0-nightly-20231013":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231013","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231013","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-42C3sA/7v0zb9DSrKc3bt6JbHyfJX/8usTFt0zP2A9frTWHvWxUJGz50SuvmeRLncD/l5tY9fhMu9a51s16v9Q==","shasum":"e97f07a5256733f8a94af49fa6366e67eb16497e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231013.tgz","fileCount":11,"unpackedSize":19063861,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIA64rjmmqIhHEKzRasWZ+Bn3vOsTRzTnfLtkQC5Iea9cAiAaAqC44ZWIO7eL8HhuCDjYfG/NfzPU74LMcnG4KfC7BA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231013_1697199467138_0.6406674927093676"},"_hasShrinkwrap":false},"0.0.0-nightly-20231014":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231014","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231014","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-AOFqo+O5iZPDcuA2ADQ/LR6SdZ69L0XG7apYdJopsPsuimkEN9mFOAY8DxNUj0tN3K70Jg3uAwYfrzIiapqzlA==","shasum":"97cf730ddd1edac4eb246d9a0c671c35e64b0115","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231014.tgz","fileCount":11,"unpackedSize":19064643,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCukVKPR7ew1x4NmFCcku/LLLKZqWzNSCgC26h3OmMMigIhALdRVLnQjlspSsVOJyzweUu4XpLmPdauWpy6kmlqUXN+"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231014_1697285749436_0.7782830900763389"},"_hasShrinkwrap":false},"0.0.0-nightly-20231015":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231015","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231015","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-Q95kWfMp89U2Q+myTUm/1umFEE71qnsvQWH4P/5RxvunHh5t09mbprPrvrPLL/FgxFb0J3YtfIVdUBMlNdg8/Q==","shasum":"484b275c0391d4e0941f2031daa1cf9d665591ce","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231015.tgz","fileCount":11,"unpackedSize":19064643,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIGk7HHAJaTWzilcEK8fWh1rcKc+yWCsxNCaCAYRAL96HAiEAibadeqwaFyqRmbP+/mLL2Z7IrcFi53Kj6o4lCXo1jv8="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231015_1697372113214_0.26730805771560107"},"_hasShrinkwrap":false},"0.0.0-nightly-20231016":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231016","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231016","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-ZiephPGPXLOAfAVFA+DkCYexb6B8mNwfV3C1J2pRJBlrwhAxDtmf7jCm5G58cqbIwg34npMDnfliAi2HaZzJTg==","shasum":"5d510227dde4a59551c198916dd21566b7d3821f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231016.tgz","fileCount":11,"unpackedSize":19064643,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICLzm6+rs/DbWfWDz1eD+hs2DsZ34TdKn9fgaodoIepEAiBWEo7PBMbznl06dO6D8vc++VCmLBRcZfwlEw/w83UMQA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231016_1697458764885_0.7504967669210825"},"_hasShrinkwrap":false},"0.0.0-nightly-20231017":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231017","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231017","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-TGxxxM/gzUvUelWQ7aVrahkHeGN4xPUyCjyDx80y3ES9HtFBBsPewBKwrEDOiZQjmv9Y+fr22ZuOSvARGqKG+A==","shasum":"cb6de10418888b098edc15c56cb457bde633bf7f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231017.tgz","fileCount":11,"unpackedSize":19065225,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIBC1rV+Eb/+VNo9nciSTIJurNVOFA/woPsyKDFAidBQbAiEA2gJpKN5Rq/epGQjaNzZPpZ0aClRF27Ej89lKoDbogwg="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231017_1697544950514_0.28742156502503513"},"_hasShrinkwrap":false},"0.0.0-nightly-20231018":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231018","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231018","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-xIMAU1p4o/ozijnWpicXtA5zipVAn8ctayO1nR7LbkeMwxZv+i4ezJS/LBBY8vFCD8ajktYOYqQJNpE+fkyUdg==","shasum":"7ba674117aa1468016b4377aef71747cef21b9f9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231018.tgz","fileCount":11,"unpackedSize":19065225,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIHEdhph4HKYKAHBuUx1TnnFJOk5Q6K1UXbPP/ttcJrGAAiEAvkQjqKaag+AKZ84dG/oyTuQ8mttGUWCWOS5HUSVkVU4="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231018_1697631648817_0.687942016836097"},"_hasShrinkwrap":false},"0.0.0-nightly-20231019":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231019","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231019","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-LsL6biDFwiV9GmqF+dWVuIAfKAWiYf1TU1n+F9bja6LE6bahmQzLi1LubrbwU4b91mW7Y/w1T6RkbwRKl11C6Q==","shasum":"d01f786a72af64e784b08ea79296faca5a6eb16b","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231019.tgz","fileCount":11,"unpackedSize":19065335,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDUrUOOd5my/PnqivQ0DcQdjVgP3Gj5jrV6tZub+mfx2wIhAN660+DhoEf3JNiU0fsVE3A8U9gn26Nc0JHFI69FomhA"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231019_1697717765900_0.3554522483272229"},"_hasShrinkwrap":false},"0.0.0-nightly-20231020":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231020","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231020","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-TGNEsC0M9uPn9U4a6clkKBvj97NXK+KMhHSlYpmfw1rImkfKYruJ4hpFHt32RVYUXJ5itVSQFqdXvG7S278UvA==","shasum":"2a37924876500095f097b82c688dca4f50c273be","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231020.tgz","fileCount":11,"unpackedSize":19065379,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDlY7rGQDNvaX4Ib+iB/2+NIAE/oV8NwKEYGTsLwQdzmQIhAOHyZkbr4JwfmYxiUW5q4Hu1fBfOlqc/kIJkriKAfc9C"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231020_1697804121882_0.9633201825061268"},"_hasShrinkwrap":false},"0.0.0-nightly-20231021":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231021","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231021","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-tkrQ4cOkrt5scDYjAMATkL4SZBS7CJpESCkYc5p29BVdojUod7LZMq5tNNYqbooTU5CoMxm4M3WbTe1JcN1MZw==","shasum":"a11e96a875d2095e712c20a48e16a729a472bc4e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231021.tgz","fileCount":11,"unpackedSize":19065549,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIFrF8ax+rKLC0ZU/UuJfDZTcI1xJ5qo/ZSY3TZTq1X2MAiEA16OKegq8httrfi2YavNTV219bRPSmovOHpmJVvFBFe4="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231021_1697890595784_0.25219244940104546"},"_hasShrinkwrap":false},"0.0.0-nightly-20231022":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231022","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231022","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-VF8yofXJzDbE/CmPKa1DmZh/7rlVGvAETrNCEiJd0JD/ok0choHGTLCba2C/ZJLgPIKlME20rqWwbbPZMzUHsA==","shasum":"7aca85bb84f4747f8ca448ecb6edca33b9626169","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231022.tgz","fileCount":11,"unpackedSize":19065549,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDji7NoxqYSHk6oKDxVg3cLDbbh83Nr83uqITVAKEV7CgIgAQEZjF7gFGdDTOWXbO4eYAOECjPv2JbCuMIVlgXiGeE="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231022_1697976845647_0.3436747333774657"},"_hasShrinkwrap":false},"0.0.0-nightly-20231023":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231023","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231023","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-Kd7hNB8Bdvm6KaY3EHsEwTOr1H2KpPZxBIqKt52fIwJ7Oit/0VoHr5KkTERFn1h/C2WM46EdWFNOJovme8DCmA==","shasum":"a362bee005b0e95c3137cdd9131b8e38dd179166","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231023.tgz","fileCount":11,"unpackedSize":19065549,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCdCMmFFTvNIjSwZLHwvhpkIhS1Q69cZf34Cs8ylZtXLQIgc1oNY/2/Jt+Qn7QFMe37Vsc3qUxfCefPkhomLz9CoWU="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231023_1698063476506_0.5866850542926163"},"_hasShrinkwrap":false},"0.0.0-nightly-20231024":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231024","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231024","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-lM/Q5tgw1EE2JR+dFtb+au4F32bFy6lnc6Sv8CMEmdIvs3V1Krs4EmbkcXykYmr2iMeBD3kegL4ESCyBf8RDPQ==","shasum":"b07e1924c9fc7a59039fa24885e0d0240d03b38a","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231024.tgz","fileCount":11,"unpackedSize":19065707,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCnRyyI/i9yv37qfsQD2uRPch5OEO5AyXqiHeRsPFezpQIhAN3VnspasgurLdoWKOXucYRZ/s40gFliOoOPNT1eOJ+9"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231024_1698149570600_0.13681570060157355"},"_hasShrinkwrap":false},"0.0.0-nightly-20231025":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231025","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231025","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-8yyABkHgydOamuGvqWogQHxfwIXrc9AOcd2gK1k/ZR8M/I0MrHZdKToQjXP5hozLtCOS0jsNCoyL//2JT4z3Ww==","shasum":"6740e0929d601b7690b1601059af296d2ed9494a","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231025.tgz","fileCount":11,"unpackedSize":19065707,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIBs+GGOpu5sYW/Cc4dQ36O3VgV2tLBVuPUVOWqqW0A3VAiEAjGlcHAKM3XVIF2hBAFuQcZep170q1A2iTrSMe3VRMvU="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231025_1698236288358_0.17559820248007196"},"_hasShrinkwrap":false},"0.0.0-nightly-20231026":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231026","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231026","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-p6jqaLPdeGD0PWvoRVkuoTJyjfiv+BWyPncZTmR4L0MOERY9/oMjLYW9PruFkLb058vshv4lG6G/rqgPAt5U4g==","shasum":"3c591f6978f33c9a0e1bdc1ed41518fc238e8f3e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231026.tgz","fileCount":11,"unpackedSize":19071943,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIAeyXpBYiJMyoXkcJ1FbBJN3QWM1c2i+yaN/WhsIehd7AiAimq3Kk5GqVlfOWdOWFBPFVvNmp2poF4w6LTQRA3Cylg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231026_1698323210969_0.38079166818470234"},"_hasShrinkwrap":false},"0.0.0-nightly-20231027":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231027","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231027","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-EpY0Ih5i9sEFU0OolTGi1+tnef0pQsyKJv7FAkkdVAezVJ/S026B58HJckX7r16zk2l6AVMQiQjFnRkZ9uoEwA==","shasum":"e16648bde46da8cc97f92a3b7e9d2fe852606a0a","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231027.tgz","fileCount":11,"unpackedSize":19071975,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCnZR7aMlJuB85ZGXVNCc+WCpCDWyCHGEN1J9RjAJAAGwIhAJtckdJrIbR3r1bzLo14YAdq8Pzac+M9mi8RAHHN9mbW"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231027_1698409595895_0.871042458726518"},"_hasShrinkwrap":false},"0.0.0-nightly-20231028":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231028","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231028","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-uzp5ELNoAyol6b3MHncZ15LHcKX9L9dhGnlm+dTQKp4ejsIHLuFlXPTkHB/uGFW8HcNosIWCcn2PJ10HimmRBQ==","shasum":"1ae1ca1731743b5c6ac863c313bc79f660e05270","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231028.tgz","fileCount":11,"unpackedSize":19071975,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDy30UHecUKAyAo0Yxe30f+itFyZzXDWJG/vuOLE6H9VQIhAKLI3/JAADPlp4HOYv4wdtV+SGHXmdc91YHQoe8aykNI"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231028_1698495598763_0.3314866139603372"},"_hasShrinkwrap":false},"0.0.0-nightly-20231029":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231029","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231029","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-nZDSkLU6+NkPPxTIBiEXWIldJhtPu3G88cPYNhdN1me+xCuSHuRKohf89ghBoRiix+3l4v/zolQ6TxCtH+pR5g==","shasum":"87d5e97642295717e5ca680b8ad8def962d2d36e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231029.tgz","fileCount":11,"unpackedSize":19071975,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIF0VNOG7Q57BFwWXeb4k92GtL3FpT3zBEAxK+VumhFLDAiEA5szaErmpINGCPJC4fhrNqPS+H6jkefgMO2jSSHkzCbY="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231029_1698581775443_0.8592050203562509"},"_hasShrinkwrap":false},"0.0.0-nightly-20231030":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231030","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231030","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-AD3XxW9ppI0JgytlC8/CghHiz0wudGwstleRCWyzPF73E1KVPCdwUN2sHXkQszELXyNKhWn85CDolpaRAsBD0g==","shasum":"a4a3dd27bff832e8627a48ef61f5f944f19a2d36","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231030.tgz","fileCount":11,"unpackedSize":19071975,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQC+Jl+69f5QLtIgM/mqBdtt+eCAWk5E40AAIt6OW8zx4gIhAPyUTBU7cSR0B0mMhVqzQj+Hlzj5fGRnLRy5RZT4jFzx"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231030_1698668585207_0.037264696732652425"},"_hasShrinkwrap":false},"0.0.0-nightly-20231031":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231031","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231031","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-FXyJrU3JVMXHwKgufTGRFELBKzOFtXhOpTjrTxNvmXJ/IH7TaDIwdS0KKTWR/3xQgAMjyif/YoMXtS7G2BPcWQ==","shasum":"11c553d4fb30af20eda8a8ccd5e730748c52bc74","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231031.tgz","fileCount":11,"unpackedSize":19068450,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCG25PxAdAAOJQE61j726jItxFAsTh0LdZY1PvI65VvVAIgK/YjNGFcFeQycy35yJ773F6FnVPXAUi4DBTGiAg8tjw="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231031_1698754696773_0.5553290267928539"},"_hasShrinkwrap":false},"0.0.0-nightly-20231101":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231101","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231101","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-7fh9VlJD9O792bldEvZYgx9uxVBp7Oe5WXyK/riO1590gtmBtiOPZYISoWsxGx+2QeqXj9ffADP9KpNKuDs9+g==","shasum":"9aca901ab390a8dea648d8e86e997a04f5658e0c","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231101.tgz","fileCount":11,"unpackedSize":19077399,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCICvH54MnR0p0DY3xvvR5zNpsJnmmBXA8FDm1mZsYthMHAiEAoUIWTLqXwofBA3xUATGIUVWWzg5DQQlqDFm5LbsGeE4="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231101_1698841135597_0.7325526367505828"},"_hasShrinkwrap":false},"0.0.0-nightly-20231102":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231102","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231102","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-RFUit+uEdLZFeqDvdY/UPPA7rUCGsndThOx658mPLRSINAtXoA7NKv8MlIJDrZQeAoxSLFrzo5eyBzHeoNlxhg==","shasum":"7a66270f26813e3ff2108024f3fc5c5697d64d91","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231102.tgz","fileCount":11,"unpackedSize":19083505,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIB3ZZ1ZzZkKQUALVVuriJ8quTKv1GDjXQEECoC3SMKuzAiB46IqXRTzzYY5G+NeIFbUFFrMVpIe5Zzr6qJPxW7yTJA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231102_1698927373651_0.413182051720981"},"_hasShrinkwrap":false},"0.0.0-nightly-20231103":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231103","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231103","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-njFOwlPUnyIoYwzt0OiEbpF6jE9KkG4OwV3mmH6BxKlodEY+jv5v6Iu5J0oF34l93NXaAuUO1Xpgj1PSrRZkOg==","shasum":"14d9a7c4a264c54e9c124a75cb3322bf5df7c419","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231103.tgz","fileCount":11,"unpackedSize":19593469,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIGPCLzP9RskMCydwZTZylAB0c0keaqtG8iZij5LA0mZ3AiAqoSDaz6+PkYuWWTNxhntQ2zEFdOU8N88vGXfWPZRQKA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231103_1699013753813_0.2820669582426616"},"_hasShrinkwrap":false},"0.0.0-nightly-20231104":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231104","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231104","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-4NHdVrUnYXVOZnI/IBB+n1SNTlsfTKJzgKomjzUPtnVUolMLmLDCRvVgXzfMI2mHeIecgXVcKB0W1lqd77LI9w==","shasum":"960084946bb17d389c6173b6967c76d30b3ebb6f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231104.tgz","fileCount":11,"unpackedSize":19593469,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCQOWBxi5oBNQMoR7RXSyk94aGcdq0E4BSi80PE3qc7eAIgE4I89x03/ZQ3znrlESECByyXK44PxRtbo7V/9vH7yXs="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231104_1699100690903_0.4397781957337139"},"_hasShrinkwrap":false},"0.0.0-nightly-20231105":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231105","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231105","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-zLL1zRl0jq9VTfKzWcSsQaTlYu5aZT2IuSS49vcaZzpD2yco2L+gJRWEbp3SI71rMcXOhewXwvzETL8F72mPPA==","shasum":"61e5e694a99f39c7b26d5eb48be04e5d2f4d2e5f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231105.tgz","fileCount":11,"unpackedSize":19593469,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIGOtomIbObWAJA6yvfOwndMRkULtrLxAvtccoOq3CsUAAiEAjK4Ui6f5h8uzEuxoufYtyVj8U2zfYz6lUtPEzyYlcJI="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231105_1699190065599_0.3289659298275296"},"_hasShrinkwrap":false},"0.0.0-nightly-20231106":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231106","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231106","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-sRQguxsGidKA0wwp0Vj3G13THGlYJ8ulYT1XiK3oQdzyrR33oZUnQ/d/g85HJLa/ZCUj7ySP4FqtwaoAlfrmLA==","shasum":"7d47fcfb1ed632c462a18ddf17b836ad72799533","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231106.tgz","fileCount":11,"unpackedSize":19593469,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIDp2qLtGOXxJd7t5x6HEy0cDVZACV3ogAyjWWntiJVbjAiAlPY9mp8gSVf4dDoYdTsNLVR0uz3n1tikSfSTViC0ssA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231106_1699276501309_0.24698372993991224"},"_hasShrinkwrap":false},"0.0.0-nightly-20231107":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231107","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231107","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-qgzbWLio+ETWkBLfe1lHeU4qLmjwTgMcxg0tgR4tAdgi/FCZdvgWlO7xaHJ5JCvruVLid2FG8DHBo6ylqvPxGQ==","shasum":"30452d162797c1e74cf1e3a92538e4d7a9e5e6bd","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231107.tgz","fileCount":11,"unpackedSize":19594347,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDAsAh3P+I6S/+WQobcMz+mxVwkuG1Qz1klLbxHhFY8kAIhAJfG1+gquTW44Wny/4PQOdtxQeEwnp5yVUCnAZRXW5XT"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231107_1699363433549_0.7893627768232538"},"_hasShrinkwrap":false},"0.0.0-nightly-20231108":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231108","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231108","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-7WDtKXFMztKAaH41KpFNJxM1nUHREtf3xqC2xIQGV7wkTc4DK+1mFkGLK+0dm+MrZB8aMKS3npNyjtx8kTTnNw==","shasum":"d3fb333bfc17980101efbba476009877e0736db6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231108.tgz","fileCount":11,"unpackedSize":19594311,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDSMP4WQW35nGV/wbJAKGur1KUfeA7PI9aHZR5QQBMH9AIgSE9t7pz/3wdFtxSDWV10lRXVgd2DS7mQp3g++4pgLpE="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231108_1699449542112_0.32006629590871016"},"_hasShrinkwrap":false},"0.0.0-nightly-20231109":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231109","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231109","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-j5JL8mfz79y2NNPLWx6RDqRdAu78w1P3zwSeIe9LcjhRLZEIyzfk4r+PWJpcbYocdFcjoN2Dj6wwsBBPzevRnw==","shasum":"1c3f864ef3e0e18750c146492b8c6d2f1e7e1bb6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231109.tgz","fileCount":11,"unpackedSize":19594221,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIFtD9NsmlScuPVjgdSlqWy9sA0FvnUu2XcChf1CkFDWcAiAZXIL3nsAOa0Nc0xdH61xotGXEpS7NVqs7K/ms70BfQQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231109_1699536000603_0.9636756522740675"},"_hasShrinkwrap":false},"0.10.8":{"name":"@mediapipe/tasks-vision","version":"0.10.8","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.8","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-Rp7ll8BHrKB3wXaRFKhrltwZl1CiXGdibPxuWXvqGnKTnv8fqa/nvftYNuSbf+pbJWKYCXdBtYTITdAUTGGh0Q==","shasum":"a78e137018a19933b7a1d0e887d553d4ab833d10","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.8.tgz","fileCount":11,"unpackedSize":19594295,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICd1qk6LbP/YTLR1xticy2qX1/HYqDUL5Mu52OcZNITwAiABCUOlkfRI55Fqp7mt1/FOG7tgS+YzFqip1038952B0g=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.8_1699568461931_0.8577209737465321"},"_hasShrinkwrap":false},"0.0.0-nightly-20231110":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231110","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231110","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-rC/HXEm9iZVuwO2Sy+DbIrcdelzDwHGYlHo1kAN6B6gQgsY9hZkcMluxV6vue5v4/GexUlVq+kwkGjHmJzBY5w==","shasum":"65153ae72d80ccf4f395c7361c44dcffd6c79f62","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231110.tgz","fileCount":11,"unpackedSize":19594123,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIHV9lxcH35nfzO4Rduw7D+rrD7TJTxy5bf7fSYO35eRqAiB5wEhgZHmGp7Vedyn4WhIupR0cZlexsgcsCwXA27dITg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231110_1699622588692_0.776796669741298"},"_hasShrinkwrap":false},"0.0.0-nightly-20231111":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231111","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231111","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-h5sKxWOBB8GkkQhZUjLhp0bOLtvcplSsRoOkh6nXk3MaIXMs3P5g9EF4/vT7Oe2UWddnhoSPaUd/km6CPLaI/Q==","shasum":"b92edb09f6471f665198805dcad9976838d09a99","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231111.tgz","fileCount":11,"unpackedSize":19593881,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDBNIjA03ZW2JJmMoA7Ydc/7KZmPIr7N/ueIEtpif4ShAIgestK3AhStdmCRk80xPXcsNckx5Gf5zPZBnNDvJEo1Eo="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231111_1699708520653_0.7432856547756101"},"_hasShrinkwrap":false},"0.0.0-nightly-20231112":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231112","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231112","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-NEX3MxGhy5EMqTE7s9YAACjrFvoqrqx/3I1s/kwmOD6WkjozSz4jRCqAu8N6YWz53dNUt00zd/dFgOMeg8nKUA==","shasum":"c96843bed8cf5fb67556e1064b790bcd55596a3c","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231112.tgz","fileCount":11,"unpackedSize":19593881,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIFZ594uANRIogaeSXI6Q3rLeOo57jO8skAYdcVHRfjGCAiEAz/tnCteACUHBU5XjDN2Iyh5VLS9Qvspd1KLHYQD7VBA="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231112_1699795012286_0.26924984783378214"},"_hasShrinkwrap":false},"0.0.0-nightly-20231113":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231113","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231113","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-dG9jQjI761UdpS801ft/xfIoq/kmKB/n/uUg4PHKIbqyL9fq6VgXnb+GH1U1YpO6cH1A9mGwZEZmbewYBpU0Mw==","shasum":"c9fa2b2a1ded76c8e77f1dd85863b6122de79cae","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231113.tgz","fileCount":11,"unpackedSize":19593881,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIDnov9efSxrMmYy8MQXSY2OXvwAOf0RX48dt4CrhD7RuAiEAtX1vfgYqqL0EvicMdr2r4XbtKiQiaNtP4QPoWor36BU="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231113_1699881451068_0.42033169217906363"},"_hasShrinkwrap":false},"0.0.0-nightly-20231114":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231114","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231114","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-vYeGnGm9O/6sLyNvIx2Sc/NSHbhQIocHYots+1OCGM8/lKSSbDSb03tyIfWiAcR0kbRqhID2+FYARegtfkuJ2A==","shasum":"c24b89947771a0b14365fee9eb27b05a6693ee68","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231114.tgz","fileCount":11,"unpackedSize":19595463,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDcSJSJ1oJbaowdv4eLDflAy5aohPTpcLUr6HqK2soxtgIgTGXFI5ExQ1EjG8zs/4u88cqf84W6XR34XKqK+E1jLjU="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231114_1699968063906_0.42496802828355795"},"_hasShrinkwrap":false},"0.0.0-nightly-20231115":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231115","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231115","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-w+suJZAmXLHVGAqgp1BJoLKE8qDMLaiWMhCtMBBVZ1Blo+bMkaQSwrU+QaSJFivFzXE9XPq7usFdKUdYKP3nmQ==","shasum":"520997bc5caf7f42fcf44b2fb7a909f7c86bab59","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231115.tgz","fileCount":11,"unpackedSize":19595463,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEz57v39w5nRzSvfmqFNB1OSZaWy/C6MgaMMXPaDNw9AAiALm7WU+RlyFVXssf6Y2SetwNADeHe8HW+A6BbaBGSEww=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231115_1700054522214_0.8410125665849937"},"_hasShrinkwrap":false},"0.0.0-nightly-20231116":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231116","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231116","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-zbNMp9Od9Chq6EZ32N6kiFkjo1QeNM4MTfg8ah6ZHDEQcGZmQXIgXHIwV5hSEf8W88FP93pj7QbB5AJO8NdImA==","shasum":"4d33173bca7cff3e9902b6b0f0c86c1288048aab","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231116.tgz","fileCount":11,"unpackedSize":19595088,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDGY/vL7haZ1QWvCkdHwkB8Gudk7h5ck+xY7NeDipAabAIgBEVqbsvQIMfUssuB8ajkG/xOmi8rJkudM8+XOVSMfhI="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231116_1700140802746_0.25192999011585826"},"_hasShrinkwrap":false},"0.0.0-nightly-20231117":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231117","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231117","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-5ct/Wj3FV8ATwf5JX/fbUN1Ih2wvr+nOb0gwOzC/MsaTuIiiXOemloHlryF4Y2JPAWHKI4Y4gAcFIlBUViRfEQ==","shasum":"34df7afff04c1ffa28fc332863e818ef97d9c704","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231117.tgz","fileCount":11,"unpackedSize":19595084,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCJI6V/FaeOXPkab3qexwvytzDiwAWsYQ/So8pqdUnhyQIhAPmeH6TwSm465KptNG/gakmBEsRfzG/khRoq/D8reXCs"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231117_1700227126255_0.3828557764228997"},"_hasShrinkwrap":false},"0.0.0-nightly-20231118":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231118","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231118","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-vPsncxxmNruyAlBzv726fYtnvQb2w+bS1A8OfZNZvSP2GmWSPz+5TWUxksQsQFmj6ctUWrG3Jt9cuk990YoTuw==","shasum":"4eb36bf65986e232b5f29b6a26420c81d96e2f4e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231118.tgz","fileCount":11,"unpackedSize":19595084,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIGHvlPJwmfMRcW2j2+ImzOo0H73VgmsuvvKwbWn5NvlkAiEAmNhJgqndd+P6Aa7qsTyxvU6T/7AOdkFWRV4LitRZgUQ="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231118_1700313554186_0.5238550494830574"},"_hasShrinkwrap":false},"0.0.0-nightly-20231119":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231119","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231119","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-R9hS6Gib+UKlsXoVk1ypsAN+XQqqfWjzwEbl/+lMMhfmsN7bzR5+xFsshs818jAJUG1Qq7HM+Nh5tDhz5nw6Hw==","shasum":"5a5511985823aa740b8e8f76a70c7307c026665a","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231119.tgz","fileCount":11,"unpackedSize":19595084,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIE07MYcXhxwbSel4kSO9hoSSZmP2WvItiy8QOFqTLP4xAiEAgBrtPhq0HK7Pr0iUgq6D6wpOoQjJ+eCmesv79IdnZ0g="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231119_1700399924615_0.364519072627119"},"_hasShrinkwrap":false},"0.0.0-nightly-20231120":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231120","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231120","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-myOI17HEQsLVI6iMhkXWcDglZCt5EH8rTVIP6d8BZAK/rcy0fEy0Ba8anst3KLCUe1uuXB+Kpd5mxNl2haOm3Q==","shasum":"be9533cd17da4598b014f283718e335182387bd5","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231120.tgz","fileCount":11,"unpackedSize":19595084,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQC7dl1gg+Hi61vwoKwivYJF8ZDppTvOVbmx3maK1c4OEgIhALbUG9SEvo72QtIZmTMxYXv6HdXXiwB/xAjqVPgVlDAG"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231120_1700486229589_0.7799001819585767"},"_hasShrinkwrap":false},"0.0.0-nightly-20231121":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231121","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231121","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-sfmCn32n2XFlHQFc8j30BQXkO0/qHxAkJNcjmyO2v+ANLo+K2+DM0zi9jV8O1Ft95y84VQVoE/XgmtAxUiJ4sw==","shasum":"a1c658b583a56c34d63893184b4bcd670d275f12","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231121.tgz","fileCount":11,"unpackedSize":19595084,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEjEMxGsJRlGOF9HMc3Dmo7v+0rkNvTHKEutbzByGs7dAiAoMX7A3XW9JmKyftUP0iBbnND1EZUUFdrdYuwLdqIJ6A=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231121_1700572960122_0.2435934091986527"},"_hasShrinkwrap":false},"0.0.0-nightly-20231122":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231122","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231122","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-7R8paMjEnFGn9Ew8FzjTZI8GP4X8TwMq3e4MuUAanm6HKr1G9V/Xobfk03HwFE5eKHymslHbc0cWp6h/CxbyAg==","shasum":"915a0e79adc732a2b85a78792c4e08ebd18e5853","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231122.tgz","fileCount":11,"unpackedSize":19597927,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQC2r97c2Xl6xgipsTqD/QZdg340QjTg1K20h4Mr/RXaTgIgUSodKAT+khIhH2BYou09/4VOoAcuvI/sukuGFesVl6M="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231122_1700659132127_0.11301699198596715"},"_hasShrinkwrap":false},"0.0.0-nightly-20231123":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231123","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231123","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-7iUnyVOzszXAWDK4X3j23x9u6fW6r0ZWw0WH6tuHgKXtatkIwQvHIjf0AswiAS14mdPafwW/krrarrfjmrjzSg==","shasum":"60a1997b9acb7813d60f1202bcf961f9a84550da","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231123.tgz","fileCount":11,"unpackedSize":19597927,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQChQtQRBbRvGEeyc/ahfAb2Jwoo+I+CxgLGKOinuhn5JgIhANV+5cwC9tG3U0mpS3Njk82s/vstZAgk45X0L9QWHHv0"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231123_1700745926042_0.9728881581261652"},"_hasShrinkwrap":false},"0.0.0-nightly-20231124":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231124","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231124","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-4YxgKT03g5weV4Rvr28zAdSTUmgWnrdc5hJBTEMtKgGiW8kRp444kXsf65JKTJISp+KOiC9Icece0rTFG/BlDg==","shasum":"52683892f055de4f5ada58a1a6225040a67fc392","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231124.tgz","fileCount":11,"unpackedSize":19597927,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCJZeytgMuQ49Pp0/ONq08tIxsVvcmZIFgf8rm/DwKxPQIgL5xoW7RsIC6PLBC4iUWlzBcrcE1lmZ3iXJysynwpUf8="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231124_1700832120460_0.39896785346500785"},"_hasShrinkwrap":false},"0.0.0-nightly-20231125":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231125","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231125","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-cEWV5CzXAmKvcfzIDDcXmiW6YoAuU76FVu3VXajViaPmFc2rUOvOcCT7txcE6CCPo8dgsbnyx9bOHHHRxmGWIQ==","shasum":"e216ed3b1b9024f75d0f47a3ed282e7a22ac5980","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231125.tgz","fileCount":11,"unpackedSize":19597927,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEjjNiY9634jPv9bcRfWhanTarFGCKdrTMsaFTZREuzIAiAk7Ky4kDBOvR09PQRThD7fqdARzOoISMngKH1/Gfad8w=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231125_1700918302414_0.8428630427940034"},"_hasShrinkwrap":false},"0.0.0-nightly-20231126":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231126","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231126","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-3bEQclZkmWJTOf3XUFdtPPvVZQ5k066VeecXYCw8957KN2D1cb66ZZWlpvu+IS7BxCzfHEx7UIPTOu3l8KF3Ng==","shasum":"69b3a94259a58ae33d04f88f1d85b2778e8f9e20","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231126.tgz","fileCount":11,"unpackedSize":19597927,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDPmFEiUVPgzCtLxIZ03jmRRrC/LJc90vH0hcCe8HyWiwIgMZpCrXfdQ5R9YvV5OUkXpPpHeP3qY6YWD5bekJevHgs="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231126_1701004683560_0.008792479034469558"},"_hasShrinkwrap":false},"0.0.0-nightly-20231127":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231127","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"hhttps://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231127","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-cUFKZKIpBfgvkIiTLy8THDHaJ5x/ek4uvu0UE2QlXM6Az5jOMuixYjoY8qUc2ZTfSZIjIk1aIYXdtSodQDvA+w==","shasum":"e94533bae9cb6151b1269b7306ef221ab5132c72","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231127.tgz","fileCount":11,"unpackedSize":19597927,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDWnh1jyXNSKbIVdtGtgdg5bN9iKf1RKCgyKKS/m4bQMAIgfyvi6ZVFa6+h/tWTdChtWjhCg/gbdCtiKZFOS+6k/b0="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231127_1701091223821_0.8937094508698504"},"_hasShrinkwrap":false},"0.0.0-nightly-20231128":{"name":"@mediapipe/tasks-vision","version":"0.0.0-nightly-20231128","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.0.0-nightly-20231128","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-JUj2x/Y3umzj+vSSQHIg7qy1ZKDApRobEs631wybEKmzBwSlOaW6reF7KhxYvZE6/RT2quiRGNPtQ3r8iEuaag==","shasum":"91e540ac133556625d9f971ad9940d346060501b","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.0.0-nightly-20231128.tgz","fileCount":11,"unpackedSize":19631820,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIDZDE+Ny+hHzdWkCSpvHARZL/D44X/YhV2m2qL2dXpNYAiB8o5MEiH4UKg23bJ70RngDFSj4WUg7EQ+EqVgTHlHcDQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.0.0-nightly-20231128_1701177950724_0.15515658042942526"},"_hasShrinkwrap":false},"0.10.9-rc.20231208":{"name":"@mediapipe/tasks-vision","version":"0.10.9-rc.20231208","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.9-rc.20231208","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-251gfuihA4GuMiKs/FZIvsVG6y66bx1mcm1LPDv3iAu8WOlEzZl5+/I2PY2ZzButUw0rCrLpOOQlE3j0ZZTBAg==","shasum":"e9935c661ace5f1be40634481a12dc19a285791d","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.9-rc.20231208.tgz","fileCount":11,"unpackedSize":19630167,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIGSW8u3A20uZCqBFfVvw1F7UH4eeawke5tylJgS+11wsAiAi7EFKwR+9/uWuDOiHrT0EiQrxjTsWYC/X8pfdP3yHyw=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.9-rc.20231208_1702041479841_0.24260920821553977"},"_hasShrinkwrap":false},"0.10.9-rc.20231209":{"name":"@mediapipe/tasks-vision","version":"0.10.9-rc.20231209","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.9-rc.20231209","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-U9aG0v6xucHjyWoF8aR581xX4bIF6GfPz/LBNHzcyWpnrmicxCjGJ6ktrROikiwEc8X2ldphTw12kVIaUe5Xsg==","shasum":"3a4d70b17001a0ed33a6735cedb5197ab0a32ab1","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.9-rc.20231209.tgz","fileCount":11,"unpackedSize":19630167,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCPaOanfUdJf53bBo7VK7LevroFcmCdmg9P/BE1wTQwTQIgcqrXD9hN6/8EgoalH6yPfSALW6U7B4MFxv1nwq4Y60g="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.9-rc.20231209_1702127846390_0.14011950805261453"},"_hasShrinkwrap":false},"0.10.9-rc.20231210":{"name":"@mediapipe/tasks-vision","version":"0.10.9-rc.20231210","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.9-rc.20231210","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-9Vi7qmibem6algTKnZl7h6KLOhLvT+WMQeMN0VRTgmQQBrQ0E0AZfrG8vbzwhQck6JWJQ5MSV+GHnVhDXiDy+A==","shasum":"0259c3b0c533a5ab1ba6545ecf666c4e920531ca","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.9-rc.20231210.tgz","fileCount":11,"unpackedSize":19630167,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIBlDi3xZBVxJt7po99S0u0Dbi455/4D3DS026T9U6o5TAiA7q67C+oqwc8eof+44tSQX+yf0JrCdOYAwRwsByuDyIw=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.9-rc.20231210_1702214193874_0.33405760356873726"},"_hasShrinkwrap":false},"0.10.9-rc.20231211":{"name":"@mediapipe/tasks-vision","version":"0.10.9-rc.20231211","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.9-rc.20231211","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-2ccmACJXlVW9j+GkHc3Y92L2umphIZUrUSxX0doc/dqR6KC2UodCyiq/uagrHdZuvSxyolfqxM1/TG/ay/hDzA==","shasum":"4f30b8541f1778a4a623c8248b51c1f939132259","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.9-rc.20231211.tgz","fileCount":11,"unpackedSize":19630167,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCdK/zlRQsmgOpSNCVbGyC+UU0EUt6ecm4nArXlqig/WAIgalQms5ld35qeIl+wcHLEIil7vgHEigyjleAO4CDmwCM="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.9-rc.20231211_1702300663678_0.021397491770045907"},"_hasShrinkwrap":false},"0.10.9-rc.20231212":{"name":"@mediapipe/tasks-vision","version":"0.10.9-rc.20231212","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.9-rc.20231212","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-/2AnxRUY/7kscfNEb+xqnI3knXCbNO0dAJNjrskk8lNE+OD5Lyf7TdrJXeVhQTmo9ayEG3K4Krt0Bx8rb4pNVA==","shasum":"b3abde378fe075776d4461921f04404fa02d8e4b","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.9-rc.20231212.tgz","fileCount":11,"unpackedSize":19630949,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIHbxHyzrhoAkfR3qc4LJTXz2akpKgTKBzaMjyP9t+KFNAiEA36GdZAtFYHk3hU9q70qgwHfUM0wmdiC8PZo1E1g5Lho="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.9-rc.20231212_1702387341598_0.3766932113310806"},"_hasShrinkwrap":false},"0.10.9-rc.20231213":{"name":"@mediapipe/tasks-vision","version":"0.10.9-rc.20231213","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.9-rc.20231213","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-vuz5/HDi3njoBi9bqeWEa2NWzoQ5Y1Axin2ezUhpJqNSzhjADVjrgqrq3m4DD9bX+dZviGeIK336GEUv1EqAGw==","shasum":"afe6863b933a6bc8bae03d25181a436213d687ea","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.9-rc.20231213.tgz","fileCount":11,"unpackedSize":19712869,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIHOatNLjMeyrSg/+e+R/XRfmufQrqJQLCdZ1Lfn6aenJAiA53y/YCHgqLNRmRwsnI1gLvDMyy5HIlxfU5ARdLy2UpQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.9-rc.20231213_1702473574697_0.2349940470345575"},"_hasShrinkwrap":false},"0.10.9":{"name":"@mediapipe/tasks-vision","version":"0.10.9","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.9","_nodeVersion":"16.14.2","_npmVersion":"8.5.0","dist":{"integrity":"sha512-/gFguyJm1ng4Qr7VVH2vKO+zZcQd8wc3YafUfvBuYFX0Y5+CvrV+VNPEVkl5W/gUZF5KNKNZAiaHPULGPCIjyQ==","shasum":"fbd669f50ac2e888b2c64c9c9863927c111da02f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.9.tgz","fileCount":11,"unpackedSize":19712857,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIGW58U0N6d6DC8BP6fcAVtg5uuNdpKDfmVaAL+IQLHNpAiBDNJAPYDFs0NJ4SQxdCPR4h9XOGFEg2I3Kj3r4VX4rRA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.9_1702490636528_0.2386009718095523"},"_hasShrinkwrap":false},"0.10.10-rc.20231214":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20231214","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20231214","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-UYcFYmbk6osp9vwmt095rQIxUQCMi92h9glVgyiAM5CtT8XZRObphPzgtm8IpjhF6BKOrguWnEiH0oLXAafhQQ==","shasum":"aaad4703a1b40acbb116e451276ec808e9681dd3","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20231214.tgz","fileCount":11,"unpackedSize":19712870,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCrj5+yWJ6g/XtqM8j83MMFx3Sg6jJTd5yEy0QRkt/fIgIhANjMvqWiXMYVFDm0z+3phSACAUVOsYIzwaQ5XV1CBHSk"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20231214_1702560207717_0.5652645662902418"},"_hasShrinkwrap":false},"0.10.10-rc.20231215":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20231215","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20231215","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-gY7PZJcDyuOBler31vBRRzeCThmZ11ijQT6JoW6a4QHxdFTcY2bUWeJu6EFZT6jwQHI1QiEs7ZnIxi9ELqvnWA==","shasum":"514fbd1b797c3d30a2784fdc2f341d1f364a0f66","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20231215.tgz","fileCount":11,"unpackedSize":19712870,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIBk5h222mTbUr0pbxZMDJSG1wy3xDCD4v+t+5WmSJXKqAiBlzb6yziJvsT3uK1mZ8qxXcxcTNi89l3Rd98AYqI2bJA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20231215_1702646461238_0.9527087993093022"},"_hasShrinkwrap":false},"0.10.10-rc.20231216":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20231216","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20231216","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-MwyXqhMuP8tmYJU5njoXHU05ByMljUL2RWhTSJ9XOHk2hjgpOgNHMcHLJkS9zZnscoqmM3ja1VJVaTrgsU4tpg==","shasum":"d17fe62e5675d35ed739ac813c5f94f1c0bbeae0","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20231216.tgz","fileCount":11,"unpackedSize":19712870,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICxW/jlbIWOJAx6054hyZYyBBDN4e8HYg1Wrd6qJeYYmAiBtHzcXvbYhz11Uq0AUTZcmLw+qb2qHqLgMwZf2oHscfg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20231216_1702732756766_0.6340367752764138"},"_hasShrinkwrap":false},"0.10.10-rc.20231217":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20231217","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20231217","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-t3DFAJUSGlhhNVRdVBym9nPHLjNVhJaDN3L0qDNScZzaBWMEry0gDifW4zkXVDLC3keUVIa1xUXrex9icvDD3w==","shasum":"eaf94ed788e09ff530cfb231c5e13c7a2321d271","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20231217.tgz","fileCount":11,"unpackedSize":19712870,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIAr2Vr2/I/0yCBTeljGxKT6Ydy8PoJbqoncQPc/Zj7fuAiBx8k9Oo6VDzYgiJ2l6GDl0FhxwBZ4T8zmn8NXSgaBI2w=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20231217_1702819136223_0.5340317719407339"},"_hasShrinkwrap":false},"0.10.10-rc.20231218":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20231218","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20231218","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-TBS6TCQlF7ruohHBQFO+2lTEE9/8s9FLtC6ro6RKoeF0hqN33HJ8HW/YZP63ZCDXLORcEUPWQzvR9n0qXwSmbA==","shasum":"6fe135676c7bb2ae4808e1f4d2b43ca1c6ec2a08","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20231218.tgz","fileCount":11,"unpackedSize":19712870,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDdSSEXiOwctZbA60P4X8y7Ia75aQmhduY/7H+zYlHMDQIhAJf/PUFEARI6dKj2s2OuwMtRzdVn/BL6gznY9ogmrbBW"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20231218_1702905935370_0.3536484721311808"},"_hasShrinkwrap":false},"0.10.10-rc.20240113":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240113","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240113","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-RXXiRQt0br0ZMp2BCWkOIp5dqQnBpBJwDxnAnQ8mK528bqR3O8z5OlA39X07YqGFP3KUsqNYSSsKtCiul3YCFw==","shasum":"182e99e3f97662325ba891b8349a6dc2505c1095","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240113.tgz","fileCount":11,"unpackedSize":19765893,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDdpcX0Half/+z+Nn3bo8L3IkslROpoCSO/xg1gnKsGxAIhAJec21CzyzsTBrQUfKmgCKJRQAZWStufv5XCZfAwLdF5"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240113_1705152049057_0.40552547470525413"},"_hasShrinkwrap":false},"0.10.10-rc.20240114":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240114","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240114","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-2cBTBq/WtEHzL3Z+LkYUdBPfn6KGUhbdBwzegsHkhRIq2Xaik4AH4BMZPDlASd6FfPHdTKrthYaXEnXaBtNgVQ==","shasum":"c44c8874e3067a8c8edeb2355fcbf8bea80f6972","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240114.tgz","fileCount":11,"unpackedSize":19765893,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIGcY/3g9YqVrLW05rwrb6yrdVug7Oq33/cEIDfDV23G1AiBDxZ7SCSWSKNxFcTxUno7hCwTmA69Wo7CzfoOXKDUcKw=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240114_1705238220025_0.8750748300970013"},"_hasShrinkwrap":false},"0.10.10-rc.20240115":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240115","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240115","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-gWRlzRmsGtI1EPFx9lCAKJh/AaC0y2caGmuYfE7Yvhss47k7wYpPWA6WtT4c0F/F4Nn1BPl4g7PCYxX91fZVYA==","shasum":"928f9ebc377ebffe78ba8454d5d1cb1b1c765ba4","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240115.tgz","fileCount":11,"unpackedSize":19765893,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQD4Zq26UqOaHOXIXI/DGdB70NLkC3AjxCzZ64TwIalEiwIgB3etPxuLGsKA9y7alXh9hhHZannC3tGworRS+duzgM8="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240115_1705324945520_0.5976415632621896"},"_hasShrinkwrap":false},"0.10.10-rc.20240116":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240116","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240116","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-TUJAavtNcriR4i6LXxcbdEnuJ25x1TCsqXcWB4RrBGGp9U3PvBMo54VsfLKu5VNxJUjA5FIiDZk5vbosmHJWwA==","shasum":"5828d4d2009175a9495c974ee25c7dde24ce80e1","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240116.tgz","fileCount":11,"unpackedSize":19765893,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIF+AXsinomj9DxdchYhLaY6Jr3XBQDAnhdfh9+ldEssRAiEA6vhrOtovXwEX/ahtTxxvxK1Ls8lNaUw7T8Xp8ItshTQ="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240116_1705410996773_0.48101444897268"},"_hasShrinkwrap":false},"0.10.10-rc.20240117":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240117","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240117","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-gPe2ytN9Arq0pUgWwgtCC1+Ahh7TqIDNB2rpsBEa+yPmdSuQAeVSMmmSaBUlslyuLqBFjW+TCVYJgiWD2suguA==","shasum":"31d7dc0438ed1bb822141491e4e258cbe470e087","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240117.tgz","fileCount":11,"unpackedSize":19765893,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIHYMRP3/vwAm28x/RzaLipHFlc7O/pqyQYxxq9xAIqFjAiEA6dqVsxFOkqsoLpME5BGowHvjITUH4SpbBwhKrHOayFA="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240117_1705497552498_0.679744308277024"},"_hasShrinkwrap":false},"0.10.10-rc.20240118":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240118","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240118","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-17FGY/ttueg4rJ/yrDSAjJAiA9ukwE7/w/sRQ1Ydh4zhdQsqEiNoHk7QMXBr3cjQLJkrevbkNjrZrg4ZmtVhdQ==","shasum":"84e49b1d464ee8d0fab6f1ed95958587e7023cf4","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240118.tgz","fileCount":11,"unpackedSize":19765893,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCBSU5Vs+yongZ/7ASqz3mfEIYKvdOp5zBJowQTWz816wIhAIYbUCNf1o+P9ddPXtqA+fJuWzwqfPpeXZ08pyKc5aoW"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240118_1705584227682_0.8076962589678514"},"_hasShrinkwrap":false},"0.10.10-rc.20240119":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240119","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240119","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-iZEok1tC9NknIj173lKHSHkbvFuiYnB1xlCSXUlaxLvjvmCPOI1UwhP4VR9gLz8wFA4GAQVtvzrAiJALy8bFbQ==","shasum":"9e5d57fc2e49693fc9de6c7150823b4772cb3572","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240119.tgz","fileCount":11,"unpackedSize":19776471,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEduHhcNpzR5rAGBtCuYLagI+h9XiPlKz1kCP1CVi3oVAiBsEe+OABkmSlwkmgHTLXVK7xIgmk3Ia6X4H5EEE+mYyA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240119_1705670771690_0.4067707201898043"},"_hasShrinkwrap":false},"0.10.10-rc.20240120":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240120","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240120","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-WoamOlFrVucJbfcLbfa/5WkKxqMDBw4X3LtCVZz4Tz9fxwU3cPNB7aGx8hwzgzOI5XUN3+lWPKd8LYjH9F7iGA==","shasum":"bcb474f1bff6706230270b3b83af2d0ced2d0295","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240120.tgz","fileCount":11,"unpackedSize":19776471,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQD/5xzOLx50Vl5bl0VjeMMlJADu+A/JzPAocbtna0DcXgIhAKAxNKcZUjCLePqq7OasABX80h0UphMCmW8Me/w/I3s3"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240120_1705756763303_0.9608328667591381"},"_hasShrinkwrap":false},"0.10.10-rc.20240121":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240121","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240121","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-1ht410HEF4OmW+jNa3EpZVNp5RW0ZebWog++TJX9M9Ih6J1hDa0eGMDdZ2iTOdo/Z6Ca2OVDfFSXs3njLndn4w==","shasum":"2a11fe4e73521fa8567970902d05fdd5c0623575","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240121.tgz","fileCount":11,"unpackedSize":19776471,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDQADTBiLeZI8xj/0eJWS3a6YGRjnC9qQB2LYlTr9sCBAIgTgMRXTsIdXwYbyt64Xz5pNA2ANlE7p50DT7B0MI9Q0M="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240121_1705843102771_0.3472923953583089"},"_hasShrinkwrap":false},"0.10.10-rc.20240122":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240122","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240122","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-GOPT6NghJECAiMAi4OMv+YTDYrJLaAMg/fUZvjkduIC1ghSXC14XoN0NniH/2gs7VOX6N/O6GkOeWE8Cpr2/Xg==","shasum":"250ddaccc3f3ee26fe9bbfb06b6a8309aa11b9d3","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240122.tgz","fileCount":11,"unpackedSize":19776471,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIGqxmqVKvlqAd2GhWXweYt4wT9MKxRckH5V7/Uyqb3CUAiEA/0CA4R4xe06Lx0wV6xUUYw/KiMaJQHLAPkyhy+EVQIc="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240122_1705929638255_0.3315871062975002"},"_hasShrinkwrap":false},"0.10.10-rc.20240123":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240123","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240123","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-UCOUw1UwGV1csJ93gzuIvrnbzCW6kMxr0Fny270J7NmJnb6ZaTmY0jBVp/PetRxS5bbVXz/32jF42a0p6UP98A==","shasum":"e1fe8033888c0ad3dd61b4670445794199363982","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240123.tgz","fileCount":11,"unpackedSize":19775959,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDHnugKEZfYvKyVgLpAyb1MpPGwep5qw7fR8LVLYDWDcAIgS/9c8MmYnWLB4zQ3xQFOU+iaRSziS+9/3rfE4qIw+Fg="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240123_1706016313322_0.568528252607422"},"_hasShrinkwrap":false},"0.10.10-rc.20240124":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240124","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240124","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-Beq+yBqMSAVBtA7DFje3ZJzSqBPGFaxLp5jrBaqCJOR05IS7MGUuZQGrXiZw9x8VHEbXmNLX2zIxGnnRxA56ZA==","shasum":"ccf2837de28745dc982d40a05951d9ff80f600b6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240124.tgz","fileCount":11,"unpackedSize":19775959,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIEwT86H6ZwAsKubZpX8kTYoDVA8n4BvuZ8st5dmyUn2FAiBoVJIbM7wLEOjoo9oX6/50EJq1kHHESjMsK/zYFgSP/A=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240124_1706102449594_0.6553540426581994"},"_hasShrinkwrap":false},"0.10.10-rc.20240125":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240125","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240125","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-g/nt3fr2pqw8Gk0iBz7tIoPvnr8FMqmxzUaRVF0cb4Fymw6aLdgSMxZvs5IOKubH5Dgg4GXuMi/Nmu0uLNvMzw==","shasum":"6152dda5df64d05e505a3266a9baa6f47f333171","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240125.tgz","fileCount":11,"unpackedSize":19775959,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICkzqAL7ONWO5TrLEyUewDxvjEdEp7SLwwpI0ATg+MbjAiBVsNvx089fd/REvEPq/3wbR0EO9MUFVlhAk0MNcqwr2A=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240125_1706189098250_0.8310792200185837"},"_hasShrinkwrap":false},"0.10.10-rc.20240126":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240126","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240126","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-4klEUttGq6bhZ0hsWgTsjdzEGGxb63Y0OQt0eUpqzPj3ULI+iC+M6KFySRgwhk19tmBXApZOkq1mvwdHTQm6jw==","shasum":"eddc43d76fafc2073f1def338134afb1a5f2155a","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240126.tgz","fileCount":11,"unpackedSize":19776055,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQC3fOc4tfxwApeoe2liqh+0DAuYKkwMRQ8Lbf6+wTXijwIhAIw0MTyhWj4cmDKBg8HQ77oYvm1HDTvrQT7TlXvuUtwg"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240126_1706275579558_0.41537304172496126"},"_hasShrinkwrap":false},"0.10.10-rc.20240127":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240127","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240127","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-iDfESr1xzRMRDtnRVmJLRHqZ1XTFChISQW6XQWmCPtSdObFXPgZAbh6yBJEx1UixZJoSRffMkYdd8PYpMKKUXA==","shasum":"7f903f99f0488a7a4c245187970a064b88608aec","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240127.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIBDGe+OmlYfv4xNfegAfOnTE3j9wjDtM43oEfvUg0emgAiBO5wJYt0RBNSABD2vucyV+7jBJKL6zuwPwkdIapWUSSQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240127_1706362151919_0.598779622011645"},"_hasShrinkwrap":false},"0.10.10-rc.20240128":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240128","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240128","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-At26uu2mqnLiWu/7qtFH3UDkgubxRRB+hFRdEAHcekkBK2Du7Sfwz8zXJ/Rjc2QHmJoT8fNTGigc0R+AVVYk9Q==","shasum":"bf5218f42495bed6857e99fd83835131066c779f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240128.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIHu894rCIxqoSThSCAwBJs1x4+3I43EtGZqxHddQt2xZAiA5m1QpoMjPLZurrq7Q163qf42Dj61F6YgDpnqPOunvKg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240128_1706447999964_0.5002612076004753"},"_hasShrinkwrap":false},"0.10.10-rc.20240129":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240129","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240129","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-nyxZBvwY/l0GZRK/Ikda88tXanABneyce2dqzaMTjHf2j0ZbHninA/hV1/qKk+iN4rmHJioZq0w0MPN2zjtr5w==","shasum":"fcdbf8ec9db32e601ae3eef0368e0daded23a921","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240129.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICsLUvIfA18Gjf6EBiI5/KQyG50zrS0MnwgZFm2fF3f6AiAGvAawhYt9NdoH68rLeXLOxejNJK+pGH2eFjCM2/z+ew=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240129_1706534762775_0.6305316483519892"},"_hasShrinkwrap":false},"0.10.10-rc.20240130":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240130","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240130","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-711H7mxdpXvp0ga4Xt6MktbdrUc7kRxv/AhorhPteD6zyHA2ZLmizIabWM3wN2DyidY0X+KvrC/PbaAH9Xc75g==","shasum":"2030e1c5c94d180eecc263c6e580e34ba4b9c38c","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240130.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDOfbeMWpI3kc9aVaJy40Z7+ENiMwUUTkD6QpaETuLzqgIgUive1XGSamHgG62zC8l0wzJW+hd/vqBqD5CRrzy4lFY="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240130_1706621156770_0.9380123370798439"},"_hasShrinkwrap":false},"0.10.10-rc.20240131":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240131","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240131","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-BH8OUnJBUqz7hxKDRH2bG6lHK9Di+2tJKXEB1ipAZet2NxeRA24seBj8xogff45/4Ap7GKMRIxgBvSS8odAR+A==","shasum":"ceed0f5e2caf29ac26550249af7e9e4fc3242f68","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240131.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCVTeOB/2OWdiPIhStwxKdlzseI8Tfc+IFe5p5wL/lJcwIgcO0Z6NNmYUcVPKK30ykEBUm8RTZ0tIFxoE56Kzl8wBw="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240131_1706707717881_0.37308307893188086"},"_hasShrinkwrap":false},"0.10.10-rc.20240201":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240201","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240201","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-/G/GQmg0dyIaz8TkbvINagVME8R67idMQ9umOfHnfEvTmXjsqWbAdfL0a5gIs55mg8qrqEBeZ6HHZfDrZ2NyPg==","shasum":"b2d9e7f9ef0a2961df76406809d976d480ab19d1","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240201.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIFtleNZzWj9WMOD82UcXFNTsh/ZFJBZf4/KMZ+RM5T2vAiAaLFxIxdLH3hULWmYMHlo1v9KwbDhgq6ORN5Om3jyjgQ=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240201_1706794141239_0.4865372847881002"},"_hasShrinkwrap":false},"0.10.10-rc.20240202":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240202","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240202","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-ooLNTdT8qoevlKvJTaNyrtvLCXWsXf+Ybfe+nF+8BtuaGvYd3DXTSPN2bAk2MtceIGQHZRlsO+ecXNSCfgzglw==","shasum":"12d93ab57a4e0355f8a94c161db2c8a7c3195f70","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240202.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIGHlJZV+x2gLYSxW+G4aV44MEebwf6fxcpZXUeLwH4viAiBFFCHLcBrm2z2YvdCgZoOV3wBaeLVDwS2JrJuyrhLiQA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240202_1706880397792_0.49615576223486246"},"_hasShrinkwrap":false},"0.10.10-rc.20240203":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240203","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240203","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-jgAGMClQ0wuUmiyri8HijLLeexf0Km/UZpMfHOS0zjz4ThrD0SYzgYEKjQbuiOuD/4TTfWqzn+rbrDKDlvriPg==","shasum":"865551a8d1ddbb579dd7aff4c8b47f2424f45dc5","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240203.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCoqvsQPlu+LTd/Ymr583kT5WuVWR5lZ4HOwiXkptd/kgIhAKVC33UU6ushh5lDPNVN80LAQICe90nuyL5cBTcB8n99"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240203_1706966301603_0.8111117907442662"},"_hasShrinkwrap":false},"0.10.10-rc.20240204":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240204","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240204","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-LXS7z9VH0oJAPDEHB9lbLNH5q1W6n2esmhnKznOFpZQFXOFNiok4jNNzo3skhaVy2REL0jyKGlFxH1ezM/n4bg==","shasum":"4a4799e1b8db54849698b057e661051e560ca8ca","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240204.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCpN/r273Ig4t2bQTQ3T+JvVGsmNlvZ7Ciw7XGekNNR6wIhAPepFRoaQwubvyptfX5rpUFWsg8vAtHYiwU2UrKZnkGL"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240204_1707052727871_0.542691779656979"},"_hasShrinkwrap":false},"0.10.10-rc.20240205":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240205","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240205","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-770Waa97rvDdSJXmx2DEUagr8tk1qIcNGXpz33ob2FnstLciMUZwxdKd/AAQvFE4Z2nkg9N3ZPQGbg/OE6kdQA==","shasum":"6e1d3eda31722d4816ec41a159638d9ede40fa50","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240205.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIALViu1HSqdM9HsXe/eg2y+bTVdWr/qj/N0feU5F5afmAiEA2XUZhtGYqaza2m0N6AQHLMmmXcDy39Fvtbzk3cele6w="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240205_1707139724961_0.35268021595464827"},"_hasShrinkwrap":false},"0.10.10-rc.20240206":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240206","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240206","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-Ej4PHDQ16lGcrhPhJugMZal00VVrkE2bGLCGH9ebUBm0ngQJuc/3r+BpzDhPLV9FeYHm47HS3pdqHvu53tyQdw==","shasum":"c4121c158d35196eb1d464317efa7de6afcf746f","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240206.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIF7ez63O8buCZeGvCXanogxKoCgw2IGJEIcPW7Kb6s2cAiB7os6UT1jSsIFsMUGHUK+U2i+YwftC4SvW6gTnzr3+nw=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240206_1707225845292_0.7104314318127671"},"_hasShrinkwrap":false},"0.10.10-rc.20240207":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240207","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240207","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-3j9hFkUpPoGEQ6L+HsKvDBz0dNtNGCN+cm01Fo01UG44QE8vRqG715XeUEsnqok7wfuiPXqQ4Eq/qIJkmtRADw==","shasum":"fdc31e9a07ee958e27a33383d3dbceefc2ccf928","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240207.tgz","fileCount":11,"unpackedSize":19777100,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCpApbjTYW0RA/W+9eakByMHXw3uzDPEE6qHpDSFEHqZAIhAJhAQStfekv67YyKYc78GZuUoGrWHgx5BhuCn/ZCnrFH"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240207_1707312289126_0.8412267966788813"},"_hasShrinkwrap":false},"0.10.10-rc.20240208":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240208","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240208","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-Aj+3nsXnKbVNxs3j3B51CS/MQimQEuiEJhBT4xvnn8+ZsY//zXdieq3Q3vlcAouHf5Xpldx54dChnN7vzQX+bw==","shasum":"8f5b89dceb425282394391e3a4d24545f7c55ad1","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240208.tgz","fileCount":11,"unpackedSize":19763224,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIBcYRRnJ9RC01P0lBZvY0Gep62Fr0UskkGZS3JRX+DERAiAopuQ2vcG5baNBRivPIBoFsieAgMTyV6rWOBbujVC4Eg=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240208_1707398727861_0.7723697881112062"},"_hasShrinkwrap":false},"0.10.10-rc.20240209":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240209","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240209","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-5V4gBBqa2alxNyoICN665KSTUvx0OtqLUXpnsSycvEEwtdU517hoL/dTDHtwyAmkAjJ4K6vkXbbKzbnli4BnpQ==","shasum":"3df96cdd31e91e965cabfb0e61cc61c56a1035ed","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240209.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDqUI7OcTFxeJCWA6T+257yHgBv5pBGTMWrhFIfRM8UgwIgfD4CBIYKYV6DOm+em2j/yylV36SXOfegdnRN18RrS1Q="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240209_1707485398151_0.36160023829982"},"_hasShrinkwrap":false},"0.10.10-rc.20240210":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240210","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240210","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-dODGyNdCbiETtWi6ojTNHiJbTwySkCXHgOIo7U3ujK+AiZKpEgZRTO5XOBBBiHCyNQwiUMXsZMmRcC50HkFOig==","shasum":"0bd026cbd8d0b0b4939c238b3bf783443d65b0a7","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240210.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIBwGU5Idi+19u33LmkjF+CaZkgqiLvoIGWDfuTrfJm/vAiBggRnNl8jax0i+/47DAjzBeBkHzYbgkS1PxIW1vR/oaA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240210_1707571138454_0.6433623464892786"},"_hasShrinkwrap":false},"0.10.10-rc.20240211":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240211","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240211","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-t0MR54C0Wd3WDvcOazCMO0HolduN9tOS6iY63CpNg7ZgE5SyjSmv472FSODHzegtnof8OiN8S0nNYyOAW2jaJg==","shasum":"9d4a43dee3a4980816fed969924ca19f460ad704","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240211.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICGLTA+L6BvLxkQAdYMNEWXBNjc3jB4ETZjiSca265p9AiAZonyzQ/tcuJWkStAXCNv/GwX0g+jc2OPTCupkOTborA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240211_1707657696507_0.30546954904698453"},"_hasShrinkwrap":false},"0.10.10-rc.20240212":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240212","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240212","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-6truN6z3Dz+rGjijYbSYOxzo6R8c2VMyr5HqwE3Ykp9TiKjVahOO/QMP5PmCvcEoNs4hRldFpJwyi3RUmdHxJQ==","shasum":"54a1ecde88e8eea0afe55f2ec1340bea216ef2a9","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240212.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIEsNvjCkLBs65cDDXWZsylxJEBhNk+IWiWi5FpFBrrZuAiEA2ZvXkuBTrLROL6TIrXSDrxi26fWimuDzFTnsF4O2uuc="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240212_1707744498316_0.6187312342814155"},"_hasShrinkwrap":false},"0.10.10-rc.20240213":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240213","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240213","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-5CRQUI21ScOsXpfGUboE/X5VCJFBQj6JSqamjmZFS3N3s8ZTMO8o2xX8S0ZuZMwF2loh3q+IrVtxoJoCtjL+6Q==","shasum":"802095060fcbf952b0b25aa3a50eb362cb2815af","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240213.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCvKVuXEolPqVQoRBANmyrOE6hPrw88Usv/MLXdExCQaQIgJvi1jLoOMIXx219s473BkoQyb9RvQ7rEkk7HT4gPL6I="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240213_1707830768637_0.3824084706818449"},"_hasShrinkwrap":false},"0.10.10-rc.20240214":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240214","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240214","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-U1l5787xolGi9v/oqo9dBA7tte+5eBlqhoIVwvYzQ/NEw9YOgMi17ttfhIrs2hejNSonYe6GPS4lU8BMsMSbnQ==","shasum":"50b86547c9d59689e1df7c267ad9fdc2c61d6a16","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240214.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDkFFOA8tdEv6XxQKsc/cLD5u1jIGWaec660PKxEqlvTQIgI/aIWLpRYY4msvaCLwYKIvMQUBFD8RlOR1gECiSGs7w="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240214_1707917875953_0.6244743807740158"},"_hasShrinkwrap":false},"0.10.10-rc.20240215":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240215","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240215","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-vDfgC5kI3HGTNMYO+FqADuJ2iAc0WxKZcDifrJ/wKcKpVzeEja05TcDTixmq0doR32v/5iuWtuApATtpWRCdZg==","shasum":"f6821ba8bf3106c94c116b10921fbee97f262f1a","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240215.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCfKF5CeXfw9haViIB0SR+kyINFZxNL+O7K93A4p7/86AIgFqrPsHWiJWT1aAq7D6PAqnNv4/AXAyhhzp+U3r982Eo="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240215_1708003712334_0.7242937501550692"},"_hasShrinkwrap":false},"0.10.10-rc.20240216":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240216","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240216","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-+3zIDUomvzbHugJwHkmXDrr68NpmIzQ39g1ZKaYKNK3ZJZqucxAeWn0UBxXmrXLVBomJv766cftW3+zNR8RU7Q==","shasum":"9753bc781f4d0b44d155ed540555697fafb7af68","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240216.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCHavQQ2svup2OGkeCESApN21A5i8jU/kGzEJcYLMMkDwIhAJilONurac0FpeL+zlj+ZG3B19E1ezkWY6JLzVLWO3Ay"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240216_1708090136884_0.4922101718428413"},"_hasShrinkwrap":false},"0.10.10-rc.20240217":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240217","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240217","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-GdVhjk7DZ5Mg71BHtbO33LEDby2goJDSmqzCjpWpukIFgG12VyZkH9mOJvG8RvvjycGrPCnw1Y/1/OLuaIlrNw==","shasum":"39ac86806b5a11662e4de6843208fc5bceaf3e5e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240217.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIH+65S0QaLLAB6MEArG0fWlsWgVdP9M7+Ok+8/v269Q9AiAaklQSzFm0dqHnCGsMTx+YnHXxRFOkAb+bZaKZifKP9g=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240217_1708176254852_0.2011721796626187"},"_hasShrinkwrap":false},"0.10.10-rc.20240218":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240218","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240218","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-W5hU253+4CrCWypV+WFSJqz0oBms5j4a8eZ11e4mDPippWuGo2uT0rtBcumlhy4kMAW34TL8dPqgN2R2hEtPIg==","shasum":"1610e0ae47a04538eddbabd00a6ab3ec16850a18","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240218.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIE8q89Ao4xVuDY4WmwWCYbZEodHrk3KW8LvPZ9C6W8tIAiAZCcks20DpdiPhr7390GLOEbfgh2+8MRQs3h6HsM7Lww=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240218_1708262329365_0.9167642421086835"},"_hasShrinkwrap":false},"0.10.10-rc.20240219":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240219","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240219","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-VbwzmWrd20KFF5u3KFgmazSgwh8a9V6/uK8fc5NI1LtPtnunyaRzrnuGj120wAhh0wOAlspVI4jsxyqsS8OUvA==","shasum":"20079906802102943a9567483312b542e358d6be","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240219.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDn2bGqV+ILEq0ikTYkVqnTSW+ZXSbx/CkuXHQ1qA7iIAIhAI3ZD4p5b4/HUsjCmZXAuo4qyo47ww93AvXDS7BUAuYu"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240219_1708348973780_0.7483136479695347"},"_hasShrinkwrap":false},"0.10.10-rc.20240220":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240220","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240220","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-WcENt0Pi5OqSNvuvziyXwUewB07nNv6k0ad2KKU/qkA3bKM8jx0Nj4nfhDwdPvJ8x46HfzvyqcudTjqVFm64Vg==","shasum":"11c98226b9c32c99f17db5b4978c86e0cf7f7468","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240220.tgz","fileCount":11,"unpackedSize":19761354,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIGdb49s80W3TJ9SFR4g1dHloBIG1ZFiZNv2Padc0LCKWAiEA7M6bmkznXkFcsiyywzp8alluFHtxITqStYtNMhRGQ7M="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240220_1708435537225_0.02279113202084515"},"_hasShrinkwrap":false},"0.10.10-rc.20240221":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240221","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240221","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-M8zlNwT7E+/32EG7W8tNaR1vEc7uVc4p5J+L9pQu0k79WWsne13H5uroqexML2BJ0zTEVnTcRY4w60vESYbRSA==","shasum":"86da5cac91f4b5d92f6c22a5342d1c6dbad33170","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240221.tgz","fileCount":11,"unpackedSize":19762166,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIAFH2FmG7y3Zud+5JkMydqhynegnKDgWgPZlQONgdKRGAiEA45DtbQLBoYZQZv6u/8i33s3zdZH0kyiN6iVfkl1OGxc="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240221_1708521814268_0.6392435695702863"},"_hasShrinkwrap":false},"0.10.10-rc.20240222":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240222","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240222","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-ttrzdo/XG3HEKOiut+5NVj9Xyp7ThKr9KhhHJyue6nckRDddkeV/hI4A6fHnBv40DWxId9xOVKkdbcXFXN/Nxw==","shasum":"3df48ec9dcc5ea6f900457cddd63582c40022407","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240222.tgz","fileCount":11,"unpackedSize":20158825,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQCtnTTSIqGCnvlHTM4agakmePVBpTk5IkUVwvayocPnUgIgZoI1ljE92hjSvuPjLmZ4d8Ptvg+nDKoEysd2dwOrw/A="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240222_1708608793347_0.771070528042958"},"_hasShrinkwrap":false},"0.10.10":{"name":"@mediapipe/tasks-vision","version":"0.10.10","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"_id":"@mediapipe/tasks-vision@0.10.10","_nodeVersion":"16.16.0","_npmVersion":"8.11.0","dist":{"integrity":"sha512-XEm7JdAsRUVTse0HeEK77tkcjvIiC8iiR4ArxujDShdX5eSyQnH8GlMjPCFiQkJS46+XEynbnoMkV36caNI2VA==","shasum":"1650c85e699682add4d45ddb21705f941e582d3e","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10.tgz","fileCount":11,"unpackedSize":20158813,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDSZN5w9RT/BY0QVhskzVqvqQUZdz3Ql68WAXM4ZUmpxAIhAK3pt4J1tFxC344P+tL9aPQj8L5fiPpL41XXQKy6L5bt"}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10_1708623402082_0.4556318926385008"},"_hasShrinkwrap":false},"0.10.10-rc.20240223":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240223","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240223","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-lu6kEA91/R+BxnQnmQOP2cWjYJdjjZTU3gBgjckptZutrkUW9r8f/IAMR3qZ3OZbbtbhguo1EM0mJ0UZXlfAqQ==","shasum":"9b8bf3e26028c51843710780c80133ce55e93e31","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240223.tgz","fileCount":11,"unpackedSize":20158825,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIFTSuZGHL/1A5gsInuUPWdj9esdp3SCdIfp6rQyVAgTnAiBKUA5hgjNwEZlV4kWuZu3PVZ7VI3ri18eUvv4bZAiMOA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240223_1708694739206_0.8309525965218914"},"_hasShrinkwrap":false},"0.10.10-rc.20240224":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240224","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240224","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-9VpWffqqbiLVOQfNCtxYMZ/2nmtcHn589undAO1qb5w6pTf/aOPihel7iQkEOzIzf8Hw5lC1Uxv5tgZUkpMRaQ==","shasum":"a0d2836e6917d7ab498206223c2e3de71443fa62","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240224.tgz","fileCount":11,"unpackedSize":20158825,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQC98aPn4khOs1l7rzbtIjZwdVTFVO1jwXpwurf3hQdEDAIgP8IpffYWdY6/BQdQHUEWgmsxfFqji6TZVEHGWSvFhJs="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240224_1708780691946_0.8238453567605548"},"_hasShrinkwrap":false},"0.10.10-rc.20240225":{"name":"@mediapipe/tasks-vision","version":"0.10.10-rc.20240225","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.10-rc.20240225","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-OgBHd4QBXVNZBM/PqtH5IVWdE3JmpH8dEjVsCL5iygHEDGcBWJTe8NAp113fKaZoYLHZg6Ln1HTnmQisacaCRw==","shasum":"84f0f84f9f663e30cfe0049352addbf7d0cdcdb6","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.10-rc.20240225.tgz","fileCount":11,"unpackedSize":20158825,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIFNUrFNlXOApUuAecjxDDpFxHhZG19j2KrS4J8O67j0OAiAIrRZOLMUqKt4PtNVGmgX4GTzuniyIypyUEMOZNAPEBA=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.10-rc.20240225_1708867079487_0.35037374404168986"},"_hasShrinkwrap":false},"0.10.11-rc.20240226":{"name":"@mediapipe/tasks-vision","version":"0.10.11-rc.20240226","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.11-rc.20240226","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-ZRCJ/ePHmw38SkCLAIh/HQy/xLh8mn3qvn4rhyJI/bJgEYjShZfA4vcebhaKJXVcM5E873olYah5aAGQw/esww==","shasum":"8779fde352fd9ef595db1bee1976a5c4ed4b9496","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.11-rc.20240226.tgz","fileCount":11,"unpackedSize":20158825,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCICFWjmX+n6EuuFVt2xrsKWG/VnpINq2xp7PiXKB6LxOjAiEAwttEGOp+5OZ89ZAw48l2AGww8/i75t8ZKOeBHZVvDpc="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.11-rc.20240226_1708953763292_0.6592977081245606"},"_hasShrinkwrap":false},"0.10.11-rc.20240227":{"name":"@mediapipe/tasks-vision","version":"0.10.11-rc.20240227","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.11-rc.20240227","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-+qofy6W2QThCQX5+z2Zp+lO0c6YEHyL0xejEzmcDI9bHVQwV+yM/SRY7DbJRN4O1rnoNdk/wk4niL5hd20qq/A==","shasum":"6bef86406397f53a21069e3ec34a1a72da8ac318","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.11-rc.20240227.tgz","fileCount":11,"unpackedSize":20158873,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIE9IN0JS7dGmgPKfbz9GHUByTvnMaCh+aj2OW47RTMWbAiBNcDCnXtdqyI8yCh0C3F9DRH0BuOi4HcsCyi0xd8Gl8Q=="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.11-rc.20240227_1709040090455_0.9221698171928063"},"_hasShrinkwrap":false},"0.10.11-rc.20240228":{"name":"@mediapipe/tasks-vision","version":"0.10.11-rc.20240228","description":"MediaPipe Vision Tasks","main":"vision_bundle.cjs","browser":"vision_bundle.mjs","module":"vision_bundle.mjs","exports":{"import":"./vision_bundle.mjs","require":"./vision_bundle.cjs","default":"./vision_bundle.mjs","types":"./vision.d.ts"},"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","type":"module","types":"vision.d.ts","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"readme":"# MediaPipe Tasks Vision Package\n\nThis package contains the vision tasks for MediaPipe.\n\n## Face Detector\n\nThe MediaPipe Face Detector task lets you detect the presence and location of\nfaces within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceDetector = await FaceDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = faceDetector.detect(image);\n```\n\nFor more information, refer to the [Face Detector](https://developers.google.com/mediapipe/solutions/vision/face_detector/web_js) documentation.\n\n## Face Landmarker\n\nThe MediaPipe Face Landmarker task lets you detect the landmarks of faces in\nan image. You can use this Task to localize key points of a face and render\nvisual effects over the faces.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceLandmarker = await FaceLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = faceLandmarker.detect(image);\n```\n\nFor more information, refer to the [Face Landmarker](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js) documentation.\n\n## Face Stylizer\n\nThe MediaPipe Face Stylizer lets you perform face stylization on images.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst faceStylizer = await FaceStylizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/1/blaze_face_stylizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst stylizedImage = faceStylizer.stylize(image);\n```\n\n## Gesture Recognizer\n\nThe MediaPipe Gesture Recognizer task lets you recognize hand gestures in real\ntime, and provides the recognized hand gesture results along with the landmarks\nof the detected hands. You can use this task to recognize specific hand gestures\nfrom a user, and invoke application features that correspond to those gestures.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst gestureRecognizer = await GestureRecognizer.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst recognitions = gestureRecognizer.recognize(image);\n```\n\nFor more information, refer to the [Gesture Recognizer](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/web_js) documentation.\n\n## Hand Landmarker\n\nThe MediaPipe Hand Landmarker task lets you detect the landmarks of the hands in\nan image. You can use this Task to localize key points of the hands and render\nvisual effects over the hands.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst handLandmarker = await HandLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = handLandmarker.detect(image);\n```\n\nFor more information, refer to the [Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/web_js) documentation.\n\n## Image Classifier\n\nThe MediaPipe Image Classifier task lets you perform classification on images.\nYou can use this task to identify what an image represents among a set of\ncategories defined at training time.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageClassifier = await ImageClassifier.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst classifications = imageClassifier.classify(image);\n```\n\nFor more information, refer to the [Image Classifier](https://developers.google.com/mediapipe/solutions/vision/image_classifier/web_js) documentation.\n\n## Image Embedder\n\nThe MediaPipe Image Embedder extracts embeddings from an image.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageEmbedder = await ImageEmbedder.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst embeddings = imageSegmenter.embed(image);\n```\n\n## Image Segmenter\n\nThe MediaPipe Image Segmenter lets you segment an image into categories.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst imageSegmenter = await ImageSegmenter.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nimageSegmenter.segment(image, (masks, width, height) => {\n  ...\n});\n```\n\nFor more information, refer to the [Image Segmenter](https://developers.google.com/mediapipe/solutions/vision/image_segmenter/web_js) documentation.\n\n## Interactive Segmenter\n\nThe MediaPipe Interactive Segmenter lets you select a region of interest to\nsegment an image by.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst interactiveSegmenter = await InteractiveSegmenter.createFromModelPath(\n    vision,\n    \"https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\ninteractiveSegmenter.segment(image, { keypoint: { x: 0.1, y: 0.2 } },\n    (masks, width, height) => { ... }\n);\n```\n\nFor more information, refer to the [Interactive Segmenter](https://developers.google.com/mediapipe/solutions/vision/interactive_segmenter/web_js) documentation.\n\n## Object Detector\n\nThe MediaPipe Object Detector task lets you detect the presence and location of\nmultiple classes of objects within images or videos.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst objectDetector = await ObjectDetector.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite\"\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst detections = objectDetector.detect(image);\n```\n\nFor more information, refer to the [Object Detector](https://developers.google.com/mediapipe/solutions/vision/object_detector/web_js) documentation.\n\n## Pose Landmarker\n\nThe MediaPipe Pose Landmarker task lets you detect the landmarks of body poses\nin an image. You can use this Task to localize key points of a pose and render\nvisual effects over the body.\n\n```\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm\"\n);\nconst poseLandmarker = await PoseLandmarker.createFromModelPath(vision,\n    \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\n);\nconst image = document.getElementById(\"image\") as HTMLImageElement;\nconst landmarks = poseLandmarker.detect(image);\n```\n\nFor more information, refer to the [Pose Landmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js) documentation.\n","readmeFilename":"README.md","_id":"@mediapipe/tasks-vision@0.10.11-rc.20240228","_nodeVersion":"19.9.0","_npmVersion":"9.6.3","dist":{"integrity":"sha512-uCD4cayeQNHcd9IOX3eWQW+P/8eXuI2T9onnOjdACrKaLvczel8HRb3EZqBDtBiEOQl3YARgtokzWHp2RcWDtg==","shasum":"7233787713710577dc658d339126f04dce7a03bd","tarball":"https://registry.npmjs.org/@mediapipe/tasks-vision/-/tasks-vision-0.10.11-rc.20240228.tgz","fileCount":11,"unpackedSize":20158873,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIAtDJ3w/nPS1qkIUfcBf8ItIia1Nx1RdgqFye6OU7lwgAiEAxqx5D60UELgIz2vLRiJFyLi/AT8TEKTEVwdiECFhTOs="}]},"_npmUser":{"name":"mrschmidt","email":"mrschmidt@google.com"},"directories":{},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/tasks-vision_0.10.11-rc.20240228_1709127262964_0.30867664755884716"},"_hasShrinkwrap":false}},"time":{"created":"2022-11-14T20:24:35.500Z","0.1.0-alpha-1668420867":"2022-11-14T20:24:35.838Z","modified":"2024-02-28T13:34:23.672Z","0.1.0-alpha-1668420868":"2022-11-14T20:39:54.967Z","0.1.0-alpha-1668548448":"2022-11-15T21:50:28.044Z","0.1.0-alpha-1668548449":"2022-11-16T01:22:30.653Z","0.1.0-alpha-1668548451":"2022-11-16T05:20:15.979Z","0.1.0-alpha-1668548452":"2022-11-16T05:58:58.377Z","0.1.0-alpha-1668548453":"2022-11-16T06:43:16.934Z","0.1.0-alpha-1668548454":"2022-11-16T07:37:54.092Z","0.1.0-alpha-1668655831":"2022-11-17T03:57:11.475Z","0.1.0-alpha-1668661712":"2022-11-17T05:16:44.566Z","0.1.0-alpha-1668661712-patch-1":"2022-11-22T05:00:08.244Z","0.1.0-alpha-1669754728":"2022-11-29T20:59:12.243Z","0.1.0-alpha-1670012900":"2022-12-02T20:41:33.913Z","0.1.0-alpha-1":"2022-12-06T22:44:46.785Z","0.1.0-alpha-2":"2023-01-11T22:12:48.825Z","0.1.0-alpha-3":"2023-01-18T16:16:11.606Z","0.1.0-alpha-4":"2023-02-07T17:13:21.945Z","0.1.0-alpha-5":"2023-03-23T18:36:25.633Z","0.1.0-alpha-6":"2023-03-27T17:09:38.496Z","0.1.0-alpha-7":"2023-03-28T03:04:55.214Z","0.1.0-alpha-8":"2023-04-06T19:14:30.467Z","0.1.0-alpha-9":"2023-04-11T19:31:21.649Z","0.1.0-alpha-10":"2023-04-13T15:54:59.513Z","0.1.0-alpha-11":"2023-04-14T15:51:15.209Z","0.1.0-alpha-12":"2023-04-18T22:04:47.921Z","0.1.0-alpha-13":"2023-04-27T23:52:13.242Z","0.1.0-alpha-14":"2023-05-08T23:29:39.644Z","0.1.0-alpha-15":"2023-05-09T21:30:03.142Z","0.1.0-alpha-16":"2023-05-09T21:54:19.891Z","0.1.0-alpha-17":"2023-05-10T03:28:00.637Z","0.10.0":"2023-05-10T14:52:13.985Z","0.10.1":"2023-06-05T18:51:10.244Z","0.10.2-rc1":"2023-06-12T18:01:48.067Z","0.10.2-rc2":"2023-06-12T18:36:07.378Z","0.10.2":"2023-07-10T17:10:35.039Z","0.10.3":"2023-08-01T18:19:54.480Z","0.10.4":"2023-08-23T18:59:26.985Z","0.10.5":"2023-09-14T16:31:33.928Z","0.10.6":"2023-09-15T20:31:26.376Z","20230919.0.0":"2023-09-19T21:32:23.298Z","20230920.0.0":"2023-09-20T12:17:43.268Z","0.0.0-nightly-20230920":"2023-09-20T17:45:46.369Z","0.0.0-nightly-20230921":"2023-09-21T12:16:29.925Z","0.0.0-nightly-20230922":"2023-09-22T04:46:15.714Z","0.0.0-nightly-20230923":"2023-09-23T12:16:09.668Z","0.0.0-nightly-20230924":"2023-09-24T12:14:57.679Z","0.0.0-nightly-20230925":"2023-09-25T12:24:52.706Z","0.0.0-nightly-20230926":"2023-09-26T17:54:45.757Z","0.0.0-nightly-20230927":"2023-09-27T12:21:09.570Z","0.0.0-nightly-20230928":"2023-09-28T04:29:57.748Z","0.0.0-nightly-20230929":"2023-09-29T12:18:42.619Z","0.0.0-nightly-20230930":"2023-09-30T04:15:26.577Z","0.0.0-nightly-20231001":"2023-10-01T12:18:44.002Z","0.0.0-nightly-20231002":"2023-10-02T12:15:22.486Z","0.0.0-nightly-20231003":"2023-10-03T12:17:13.452Z","0.0.0-nightly-20231004":"2023-10-04T04:56:45.020Z","0.0.0-nightly-20231006":"2023-10-06T17:28:25.101Z","0.0.0-nightly-20231007":"2023-10-07T12:17:36.647Z","0.0.0-nightly-20231008":"2023-10-08T12:14:44.605Z","0.0.0-nightly-20231009":"2023-10-09T12:16:36.989Z","0.10.7":"2023-10-09T20:36:31.305Z","0.0.0-nightly-20231010":"2023-10-10T12:15:25.007Z","0.0.0-nightly-20231011":"2023-10-11T12:17:16.264Z","0.0.0-nightly-20231012":"2023-10-12T12:17:30.209Z","0.0.0-nightly-20231013":"2023-10-13T12:17:47.668Z","0.0.0-nightly-20231014":"2023-10-14T12:15:49.765Z","0.0.0-nightly-20231015":"2023-10-15T12:15:13.561Z","0.0.0-nightly-20231016":"2023-10-16T12:19:25.259Z","0.0.0-nightly-20231017":"2023-10-17T12:15:50.885Z","0.0.0-nightly-20231018":"2023-10-18T12:20:49.209Z","0.0.0-nightly-20231019":"2023-10-19T12:16:06.537Z","0.0.0-nightly-20231020":"2023-10-20T12:15:22.314Z","0.0.0-nightly-20231021":"2023-10-21T12:16:36.137Z","0.0.0-nightly-20231022":"2023-10-22T12:14:05.906Z","0.0.0-nightly-20231023":"2023-10-23T12:17:56.873Z","0.0.0-nightly-20231024":"2023-10-24T12:12:51.044Z","0.0.0-nightly-20231025":"2023-10-25T12:18:08.835Z","0.0.0-nightly-20231026":"2023-10-26T12:26:51.376Z","0.0.0-nightly-20231027":"2023-10-27T12:26:36.486Z","0.0.0-nightly-20231028":"2023-10-28T12:19:59.176Z","0.0.0-nightly-20231029":"2023-10-29T12:16:15.813Z","0.0.0-nightly-20231030":"2023-10-30T12:23:05.550Z","0.0.0-nightly-20231031":"2023-10-31T12:18:17.152Z","0.0.0-nightly-20231101":"2023-11-01T12:18:56.022Z","0.0.0-nightly-20231102":"2023-11-02T12:16:13.984Z","0.0.0-nightly-20231103":"2023-11-03T12:15:54.302Z","0.0.0-nightly-20231104":"2023-11-04T12:24:51.306Z","0.0.0-nightly-20231105":"2023-11-05T13:14:25.961Z","0.0.0-nightly-20231106":"2023-11-06T13:15:01.718Z","0.0.0-nightly-20231107":"2023-11-07T13:23:53.835Z","0.0.0-nightly-20231108":"2023-11-08T13:19:02.565Z","0.0.0-nightly-20231109":"2023-11-09T13:20:00.934Z","0.10.8":"2023-11-09T22:21:02.373Z","0.0.0-nightly-20231110":"2023-11-10T13:23:09.033Z","0.0.0-nightly-20231111":"2023-11-11T13:15:21.096Z","0.0.0-nightly-20231112":"2023-11-12T13:16:52.659Z","0.0.0-nightly-20231113":"2023-11-13T13:17:31.405Z","0.0.0-nightly-20231114":"2023-11-14T13:21:04.155Z","0.0.0-nightly-20231115":"2023-11-15T13:22:02.478Z","0.0.0-nightly-20231116":"2023-11-16T13:20:03.121Z","0.0.0-nightly-20231117":"2023-11-17T13:18:46.636Z","0.0.0-nightly-20231118":"2023-11-18T13:19:14.570Z","0.0.0-nightly-20231119":"2023-11-19T13:18:44.951Z","0.0.0-nightly-20231120":"2023-11-20T13:17:09.930Z","0.0.0-nightly-20231121":"2023-11-21T13:22:40.502Z","0.0.0-nightly-20231122":"2023-11-22T13:18:52.399Z","0.0.0-nightly-20231123":"2023-11-23T13:25:26.340Z","0.0.0-nightly-20231124":"2023-11-24T13:22:00.797Z","0.0.0-nightly-20231125":"2023-11-25T13:18:22.716Z","0.0.0-nightly-20231126":"2023-11-26T13:18:03.841Z","0.0.0-nightly-20231127":"2023-11-27T13:20:24.119Z","0.0.0-nightly-20231128":"2023-11-28T13:25:51.053Z","0.10.9-rc.20231208":"2023-12-08T13:18:00.174Z","0.10.9-rc.20231209":"2023-12-09T13:17:26.672Z","0.10.9-rc.20231210":"2023-12-10T13:16:34.200Z","0.10.9-rc.20231211":"2023-12-11T13:17:43.982Z","0.10.9-rc.20231212":"2023-12-12T13:22:21.909Z","0.10.9-rc.20231213":"2023-12-13T13:19:35.104Z","0.10.9":"2023-12-13T18:03:56.898Z","0.10.10-rc.20231214":"2023-12-14T13:23:28.031Z","0.10.10-rc.20231215":"2023-12-15T13:21:01.704Z","0.10.10-rc.20231216":"2023-12-16T13:19:17.131Z","0.10.10-rc.20231217":"2023-12-17T13:18:56.568Z","0.10.10-rc.20231218":"2023-12-18T13:25:35.736Z","0.10.10-rc.20240113":"2024-01-13T13:20:49.345Z","0.10.10-rc.20240114":"2024-01-14T13:17:00.338Z","0.10.10-rc.20240115":"2024-01-15T13:22:25.752Z","0.10.10-rc.20240116":"2024-01-16T13:16:37.010Z","0.10.10-rc.20240117":"2024-01-17T13:19:12.791Z","0.10.10-rc.20240118":"2024-01-18T13:23:47.960Z","0.10.10-rc.20240119":"2024-01-19T13:26:11.980Z","0.10.10-rc.20240120":"2024-01-20T13:19:23.586Z","0.10.10-rc.20240121":"2024-01-21T13:18:23.027Z","0.10.10-rc.20240122":"2024-01-22T13:20:38.587Z","0.10.10-rc.20240123":"2024-01-23T13:25:13.712Z","0.10.10-rc.20240124":"2024-01-24T13:20:49.872Z","0.10.10-rc.20240125":"2024-01-25T13:24:58.545Z","0.10.10-rc.20240126":"2024-01-26T13:26:19.834Z","0.10.10-rc.20240127":"2024-01-27T13:29:12.156Z","0.10.10-rc.20240128":"2024-01-28T13:20:00.293Z","0.10.10-rc.20240129":"2024-01-29T13:26:03.057Z","0.10.10-rc.20240130":"2024-01-30T13:25:57.086Z","0.10.10-rc.20240131":"2024-01-31T13:28:38.205Z","0.10.10-rc.20240201":"2024-02-01T13:29:01.563Z","0.10.10-rc.20240202":"2024-02-02T13:26:38.091Z","0.10.10-rc.20240203":"2024-02-03T13:18:21.901Z","0.10.10-rc.20240204":"2024-02-04T13:18:48.189Z","0.10.10-rc.20240205":"2024-02-05T13:28:45.227Z","0.10.10-rc.20240206":"2024-02-06T13:24:05.590Z","0.10.10-rc.20240207":"2024-02-07T13:24:49.382Z","0.10.10-rc.20240208":"2024-02-08T13:25:28.107Z","0.10.10-rc.20240209":"2024-02-09T13:29:58.460Z","0.10.10-rc.20240210":"2024-02-10T13:18:58.755Z","0.10.10-rc.20240211":"2024-02-11T13:21:36.824Z","0.10.10-rc.20240212":"2024-02-12T13:28:18.590Z","0.10.10-rc.20240213":"2024-02-13T13:26:08.899Z","0.10.10-rc.20240214":"2024-02-14T13:37:56.288Z","0.10.10-rc.20240215":"2024-02-15T13:28:32.622Z","0.10.10-rc.20240216":"2024-02-16T13:28:57.161Z","0.10.10-rc.20240217":"2024-02-17T13:24:15.158Z","0.10.10-rc.20240218":"2024-02-18T13:18:49.664Z","0.10.10-rc.20240219":"2024-02-19T13:22:54.037Z","0.10.10-rc.20240220":"2024-02-20T13:25:37.468Z","0.10.10-rc.20240221":"2024-02-21T13:23:34.538Z","0.10.10-rc.20240222":"2024-02-22T13:33:13.724Z","0.10.10":"2024-02-22T17:36:42.415Z","0.10.10-rc.20240223":"2024-02-23T13:25:39.481Z","0.10.10-rc.20240224":"2024-02-24T13:18:12.236Z","0.10.10-rc.20240225":"2024-02-25T13:17:59.766Z","0.10.11-rc.20240226":"2024-02-26T13:22:43.582Z","0.10.11-rc.20240227":"2024-02-27T13:21:30.743Z","0.10.11-rc.20240228":"2024-02-28T13:34:23.187Z"},"maintainers":[{"name":"mrschmidt","email":"mrschmidt@google.com"},{"name":"tmullen","email":"tmullen@google.com"},{"name":"dancingplatypus","email":"dancingplatypus@gmail.com"},{"name":"google-wombot","email":"node-team-npm+wombot@google.com"},{"name":"chuoling","email":"chuoling@google.com"}],"description":"MediaPipe Vision Tasks","homepage":"http://mediapipe.dev","keywords":["AR","ML","Augmented","MediaPipe","MediaPipe Tasks"],"author":{"name":"mediapipe@google.com"},"license":"Apache-2.0","readme":"","readmeFilename":""}